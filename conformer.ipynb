{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm==0.3.2 in /home/srikanth/graspenv/lib/python3.10/site-packages (0.3.2)\n",
      "Requirement already satisfied: torch>=1.0 in /home/srikanth/graspenv/lib/python3.10/site-packages (from timm==0.3.2) (2.0.0+cu118)\n",
      "Requirement already satisfied: torchvision in /home/srikanth/graspenv/lib/python3.10/site-packages (from timm==0.3.2) (0.15.1+cu118)\n",
      "Requirement already satisfied: networkx in /home/srikanth/graspenv/lib/python3.10/site-packages (from torch>=1.0->timm==0.3.2) (3.0)\n",
      "Requirement already satisfied: typing-extensions in /home/srikanth/graspenv/lib/python3.10/site-packages (from torch>=1.0->timm==0.3.2) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/srikanth/graspenv/lib/python3.10/site-packages (from torch>=1.0->timm==0.3.2) (1.12)\n",
      "Requirement already satisfied: filelock in /home/srikanth/graspenv/lib/python3.10/site-packages (from torch>=1.0->timm==0.3.2) (3.9.0)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/srikanth/graspenv/lib/python3.10/site-packages (from torch>=1.0->timm==0.3.2) (2.0.0)\n",
      "Requirement already satisfied: jinja2 in /home/srikanth/graspenv/lib/python3.10/site-packages (from torch>=1.0->timm==0.3.2) (3.1.2)\n",
      "Requirement already satisfied: lit in /home/srikanth/graspenv/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.0->timm==0.3.2) (15.0.7)\n",
      "Requirement already satisfied: cmake in /home/srikanth/graspenv/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.0->timm==0.3.2) (3.25.0)\n",
      "Requirement already satisfied: requests in /home/srikanth/graspenv/lib/python3.10/site-packages (from torchvision->timm==0.3.2) (2.31.0)\n",
      "Requirement already satisfied: numpy in /home/srikanth/graspenv/lib/python3.10/site-packages (from torchvision->timm==0.3.2) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/srikanth/graspenv/lib/python3.10/site-packages (from torchvision->timm==0.3.2) (9.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/srikanth/graspenv/lib/python3.10/site-packages (from jinja2->torch>=1.0->timm==0.3.2) (2.1.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/srikanth/graspenv/lib/python3.10/site-packages (from requests->torchvision->timm==0.3.2) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/srikanth/graspenv/lib/python3.10/site-packages (from requests->torchvision->timm==0.3.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/srikanth/graspenv/lib/python3.10/site-packages (from requests->torchvision->timm==0.3.2) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/srikanth/graspenv/lib/python3.10/site-packages (from requests->torchvision->timm==0.3.2) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/srikanth/graspenv/lib/python3.10/site-packages (from sympy->torch>=1.0->timm==0.3.2) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install timm==0.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from einops import rearrange\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler,autocast\n",
    "import torch.optim as optim\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Palmar wrist pronated', 'Pinch', 'Tripod', 'Palmar wrist neutral']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = r\"/home/srikanth/Dataset/RGB_images\"\n",
    "dataset_path = os.listdir(root_path)\n",
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = []\n",
    "\n",
    "\n",
    "for item in dataset_path:\n",
    "    #print(item)\n",
    "    all_objects = os.listdir(root_path + '/' +item)\n",
    "    for top_object in all_objects:\n",
    "        sub_objects = os.listdir(root_path  + '/' +item + '/' +top_object)\n",
    "        for sub_object in sub_objects:\n",
    "            images = os.listdir(root_path + '/' +item + '/' +top_object + '/' +sub_object)\n",
    "            for image in images:\n",
    "                class_labels.append((item,str(root_path + '/' +item + '/' +top_object + '/' +sub_object +'/' +image)))\n",
    "# class_labels\n",
    "df = pd.DataFrame(data=class_labels, columns=['labels', 'image'])\n",
    "# df\n",
    "y=list(df['labels'].values)\n",
    "# y\n",
    "image=df['image']\n",
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, y= shuffle(image,y, random_state=1)\n",
    "train_x, test_x, train_y, test_y = train_test_split(images, y, test_size=0.2, random_state=415)\n",
    "test_x = test_x.reset_index(drop=True)\n",
    "train_x = train_x.reset_index(drop=True)\n",
    "test_x, val_x, test_y, val_y = train_test_split(test_x,test_y, test_size=0.5, random_state=415)\n",
    "test_x = test_x.reset_index(drop=True)\n",
    "#train_y=list(train_y)\n",
    "train_df=pd.DataFrame({'filepaths':train_x,'labels':train_y})\n",
    "valid_df=pd.DataFrame({'filepaths':val_x,'labels':val_y})\n",
    "test_df=pd.DataFrame({'filepaths':test_x,'labels':test_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=list(train_df['labels'].unique())\n",
    "class_count=len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Palmar wrist pronated': 0, 'Pinch': 1, 'Tripod': 2, 'Palmar wrist neutral': 3}\n",
      "{0: 'Palmar wrist pronated', 1: 'Pinch', 2: 'Tripod', 3: 'Palmar wrist neutral'}\n"
     ]
    }
   ],
   "source": [
    "labels = df['labels'].unique()\n",
    "num_labels = len(labels)\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = i\n",
    "    id2label[i] = label\n",
    "\n",
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset():\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((64, 64), antialias=True),\n",
    "        transforms.Normalize( mean= [0.51158103, 0.47950193, 0.46153474],\n",
    "                             std=[0.22355489, 0.22948845, 0.24873442])\n",
    "        ])\n",
    "        self.label_mapping = label2id\n",
    "    # class ImageDataset(Dataset):\n",
    "    # def __init__(self, df, label2id, input_size=224, transform=None):\n",
    "    #     self.df = df\n",
    "    #     self.label_mapping = label2id\n",
    "    #     resize_value = self.calculate_resize_value(input_size)\n",
    "    #     self.transform = transform if transform else transforms.Compose([\n",
    "    #         transforms.Resize((resize_value, resize_value), antialias=True),\n",
    "    #         transforms.CenterCrop(input_size),\n",
    "    #         transforms.ToTensor(),\n",
    "    #         transforms.Normalize(mean=[0.51158103, 0.47950193, 0.46153474],\n",
    "    #                              std=[0.22355489, 0.22948845, 0.24873442])\n",
    "    #     ])\n",
    "\n",
    "    # def calculate_resize_value(self, input_size):\n",
    "    #     return int((256 / 224) * input_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def get_images(self, idx):\n",
    "        return self.transform(Image.open(self.df.iloc[idx]['filepaths']))\n",
    "\n",
    "    def get_labels(self, idx):\n",
    "        label = self.df.iloc[idx]['labels']\n",
    "        return torch.tensor(self.label_mapping[label], dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        train_images = self.get_images(idx)\n",
    "        train_labels = self.get_labels(idx)\n",
    "\n",
    "        return train_images, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(train_df, transform=transforms)\n",
    "val_dataset = ImageDataset(valid_df, transform=transforms)\n",
    "test_dataset = ImageDataset(test_df, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "\n",
    "from timm.models.layers import DropPath, trunc_normal_\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        # NOTE scale factor was wrong in my original version, can set manually to be compat with prev weights\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]  # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., act_layer=nn.GELU, norm_layer=partial(nn.LayerNorm, eps=1e-6)):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = Attention(\n",
    "            dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
    "        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, inplanes, outplanes, stride=1, res_conv=False, act_layer=nn.ReLU, groups=1,\n",
    "                 norm_layer=partial(nn.BatchNorm2d, eps=1e-6), drop_block=None, drop_path=None):\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        expansion = 4\n",
    "        med_planes = outplanes // expansion\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, med_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = norm_layer(med_planes)\n",
    "        self.act1 = act_layer(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(med_planes, med_planes, kernel_size=3, stride=stride, groups=groups, padding=1, bias=False)\n",
    "        self.bn2 = norm_layer(med_planes)\n",
    "        self.act2 = act_layer(inplace=True)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(med_planes, outplanes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn3 = norm_layer(outplanes)\n",
    "        self.act3 = act_layer(inplace=True)\n",
    "\n",
    "        if res_conv:\n",
    "            self.residual_conv = nn.Conv2d(inplanes, outplanes, kernel_size=1, stride=stride, padding=0, bias=False)\n",
    "            self.residual_bn = norm_layer(outplanes)\n",
    "\n",
    "        self.res_conv = res_conv\n",
    "        self.drop_block = drop_block\n",
    "        self.drop_path = drop_path\n",
    "\n",
    "    def zero_init_last_bn(self):\n",
    "        nn.init.zeros_(self.bn3.weight)\n",
    "\n",
    "    def forward(self, x, x_t=None, return_x_2=True):\n",
    "        residual = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        if self.drop_block is not None:\n",
    "            x = self.drop_block(x)\n",
    "        x = self.act1(x)\n",
    "\n",
    "        x = self.conv2(x) if x_t is None else self.conv2(x + x_t)\n",
    "        x = self.bn2(x)\n",
    "        if self.drop_block is not None:\n",
    "            x = self.drop_block(x)\n",
    "        x2 = self.act2(x)\n",
    "\n",
    "        x = self.conv3(x2)\n",
    "        x = self.bn3(x)\n",
    "        if self.drop_block is not None:\n",
    "            x = self.drop_block(x)\n",
    "\n",
    "        if self.drop_path is not None:\n",
    "            x = self.drop_path(x)\n",
    "\n",
    "        if self.res_conv:\n",
    "            residual = self.residual_conv(residual)\n",
    "            residual = self.residual_bn(residual)\n",
    "\n",
    "        x += residual\n",
    "        x = self.act3(x)\n",
    "\n",
    "        if return_x_2:\n",
    "            return x, x2\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "class FCUDown(nn.Module):\n",
    "    \"\"\" CNN feature maps -> Transformer patch embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inplanes, outplanes, dw_stride, act_layer=nn.GELU,\n",
    "                 norm_layer=partial(nn.LayerNorm, eps=1e-6)):\n",
    "        super(FCUDown, self).__init__()\n",
    "        self.dw_stride = dw_stride\n",
    "\n",
    "        self.conv_project = nn.Conv2d(inplanes, outplanes, kernel_size=1, stride=1, padding=0)\n",
    "        self.sample_pooling = nn.AvgPool2d(kernel_size=dw_stride, stride=dw_stride)\n",
    "\n",
    "        self.ln = norm_layer(outplanes)\n",
    "        self.act = act_layer()\n",
    "\n",
    "    def forward(self, x, x_t):\n",
    "        x = self.conv_project(x)  # [N, C, H, W]\n",
    "\n",
    "        x = self.sample_pooling(x).flatten(2).transpose(1, 2)\n",
    "        x = self.ln(x)\n",
    "        x = self.act(x)\n",
    "\n",
    "        x = torch.cat([x_t[:, 0][:, None, :], x], dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class FCUUp(nn.Module):\n",
    "    \"\"\" Transformer patch embeddings -> CNN feature maps\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inplanes, outplanes, up_stride, act_layer=nn.ReLU,\n",
    "                 norm_layer=partial(nn.BatchNorm2d, eps=1e-6),):\n",
    "        super(FCUUp, self).__init__()\n",
    "\n",
    "        self.up_stride = up_stride\n",
    "        self.conv_project = nn.Conv2d(inplanes, outplanes, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn = norm_layer(outplanes)\n",
    "        self.act = act_layer()\n",
    "\n",
    "    def forward(self, x, H, W):\n",
    "        B, _, C = x.shape\n",
    "        # [N, 197, 384] -> [N, 196, 384] -> [N, 384, 196] -> [N, 384, 14, 14]\n",
    "        x_r = x[:, 1:].transpose(1, 2).reshape(B, C, H, W)\n",
    "        x_r = self.act(self.bn(self.conv_project(x_r)))\n",
    "\n",
    "        return F.interpolate(x_r, size=(H * self.up_stride, W * self.up_stride))\n",
    "\n",
    "\n",
    "class Med_ConvBlock(nn.Module):\n",
    "    \"\"\" special case for Convblock with down sampling,\n",
    "    \"\"\"\n",
    "    def __init__(self, inplanes, act_layer=nn.ReLU, groups=1, norm_layer=partial(nn.BatchNorm2d, eps=1e-6),\n",
    "                 drop_block=None, drop_path=None):\n",
    "\n",
    "        super(Med_ConvBlock, self).__init__()\n",
    "\n",
    "        expansion = 4\n",
    "        med_planes = inplanes // expansion\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, med_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = norm_layer(med_planes)\n",
    "        self.act1 = act_layer(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(med_planes, med_planes, kernel_size=3, stride=1, groups=groups, padding=1, bias=False)\n",
    "        self.bn2 = norm_layer(med_planes)\n",
    "        self.act2 = act_layer(inplace=True)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(med_planes, inplanes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn3 = norm_layer(inplanes)\n",
    "        self.act3 = act_layer(inplace=True)\n",
    "\n",
    "        self.drop_block = drop_block\n",
    "        self.drop_path = drop_path\n",
    "\n",
    "    def zero_init_last_bn(self):\n",
    "        nn.init.zeros_(self.bn3.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        if self.drop_block is not None:\n",
    "            x = self.drop_block(x)\n",
    "        x = self.act1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.drop_block is not None:\n",
    "            x = self.drop_block(x)\n",
    "        x = self.act2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        if self.drop_block is not None:\n",
    "            x = self.drop_block(x)\n",
    "\n",
    "        if self.drop_path is not None:\n",
    "            x = self.drop_path(x)\n",
    "\n",
    "        x += residual\n",
    "        x = self.act3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvTransBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic module for ConvTransformer, keep feature maps for CNN block and patch embeddings for transformer encoder block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inplanes, outplanes, res_conv, stride, dw_stride, embed_dim, num_heads=12, mlp_ratio=4.,\n",
    "                 qkv_bias=False, qk_scale=None, drop_rate=0., attn_drop_rate=0., drop_path_rate=0.,\n",
    "                 last_fusion=False, num_med_block=0, groups=1):\n",
    "\n",
    "        super(ConvTransBlock, self).__init__()\n",
    "        expansion = 4\n",
    "        self.cnn_block = ConvBlock(inplanes=inplanes, outplanes=outplanes, res_conv=res_conv, stride=stride, groups=groups)\n",
    "\n",
    "        if last_fusion:\n",
    "            self.fusion_block = ConvBlock(inplanes=outplanes, outplanes=outplanes, stride=2, res_conv=True, groups=groups)\n",
    "        else:\n",
    "            self.fusion_block = ConvBlock(inplanes=outplanes, outplanes=outplanes, groups=groups)\n",
    "\n",
    "        if num_med_block > 0:\n",
    "            self.med_block = []\n",
    "            for i in range(num_med_block):\n",
    "                self.med_block.append(Med_ConvBlock(inplanes=outplanes, groups=groups))\n",
    "            self.med_block = nn.ModuleList(self.med_block)\n",
    "\n",
    "        self.squeeze_block = FCUDown(inplanes=outplanes // expansion, outplanes=embed_dim, dw_stride=dw_stride)\n",
    "\n",
    "        self.expand_block = FCUUp(inplanes=embed_dim, outplanes=outplanes // expansion, up_stride=dw_stride)\n",
    "\n",
    "        self.trans_block = Block(\n",
    "            dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "            drop=drop_rate, attn_drop=attn_drop_rate, drop_path=drop_path_rate)\n",
    "\n",
    "        self.dw_stride = dw_stride\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_med_block = num_med_block\n",
    "        self.last_fusion = last_fusion\n",
    "\n",
    "    def forward(self, x, x_t):\n",
    "        x, x2 = self.cnn_block(x)\n",
    "\n",
    "        _, _, H, W = x2.shape\n",
    "\n",
    "        x_st = self.squeeze_block(x2, x_t)\n",
    "\n",
    "        x_t = self.trans_block(x_st + x_t)\n",
    "\n",
    "        if self.num_med_block > 0:\n",
    "            for m in self.med_block:\n",
    "                x = m(x)\n",
    "\n",
    "        x_t_r = self.expand_block(x_t, H // self.dw_stride, W // self.dw_stride)\n",
    "        x = self.fusion_block(x, x_t_r, return_x_2=False)\n",
    "\n",
    "        return x, x_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONFORMER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conformer(nn.Module):\n",
    "\n",
    "    def __init__(self, patch_size=16, in_chans=3, num_classes=1000, base_channel=64, channel_ratio=4, num_med_block=0,\n",
    "                 embed_dim=768, depth=12, num_heads=12, mlp_ratio=4., qkv_bias=False, qk_scale=None,\n",
    "                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0.):\n",
    "\n",
    "        # Transformer\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = self.embed_dim = embed_dim  # num_features for consistency with other models\n",
    "        assert depth % 3 == 0\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.trans_dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
    "\n",
    "        # Classifier head\n",
    "        self.trans_norm = nn.LayerNorm(embed_dim)\n",
    "        self.trans_cls_head = nn.Linear(embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv_cls_head = nn.Linear(int(256 * channel_ratio), num_classes)\n",
    "\n",
    "        # Stem stage: get the feature maps by conv block (copied form resnet.py)\n",
    "        self.conv1 = nn.Conv2d(in_chans, 64, kernel_size=7, stride=2, padding=3, bias=False)  # 1 / 2 [112, 112]\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.act1 = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # 1 / 4 [56, 56]\n",
    "\n",
    "        # 1 stage\n",
    "        stage_1_channel = int(base_channel * channel_ratio)\n",
    "        trans_dw_stride = patch_size // 4\n",
    "        self.conv_1 = ConvBlock(inplanes=64, outplanes=stage_1_channel, res_conv=True, stride=1)\n",
    "        self.trans_patch_conv = nn.Conv2d(64, embed_dim, kernel_size=trans_dw_stride, stride=trans_dw_stride, padding=0)\n",
    "        self.trans_1 = Block(dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias,\n",
    "                             qk_scale=qk_scale, drop=drop_rate, attn_drop=attn_drop_rate, drop_path=self.trans_dpr[0],\n",
    "                             )\n",
    "\n",
    "        # 2~4 stage\n",
    "        init_stage = 2\n",
    "        fin_stage = depth // 3 + 1\n",
    "        for i in range(init_stage, fin_stage):\n",
    "            self.add_module('conv_trans_' + str(i),\n",
    "                    ConvTransBlock(\n",
    "                        stage_1_channel, stage_1_channel, False, 1, dw_stride=trans_dw_stride, embed_dim=embed_dim,\n",
    "                        num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                        drop_rate=drop_rate, attn_drop_rate=attn_drop_rate, drop_path_rate=self.trans_dpr[i-1],\n",
    "                        num_med_block=num_med_block\n",
    "                    )\n",
    "            )\n",
    "\n",
    "\n",
    "        stage_2_channel = int(base_channel * channel_ratio * 2)\n",
    "        # 5~8 stage\n",
    "        init_stage = fin_stage # 5\n",
    "        fin_stage = fin_stage + depth // 3 # 9\n",
    "        for i in range(init_stage, fin_stage):\n",
    "            s = 2 if i == init_stage else 1\n",
    "            in_channel = stage_1_channel if i == init_stage else stage_2_channel\n",
    "            res_conv = True if i == init_stage else False\n",
    "            self.add_module('conv_trans_' + str(i),\n",
    "                    ConvTransBlock(\n",
    "                        in_channel, stage_2_channel, res_conv, s, dw_stride=trans_dw_stride // 2, embed_dim=embed_dim,\n",
    "                        num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                        drop_rate=drop_rate, attn_drop_rate=attn_drop_rate, drop_path_rate=self.trans_dpr[i-1],\n",
    "                        num_med_block=num_med_block\n",
    "                    )\n",
    "            )\n",
    "\n",
    "        stage_3_channel = int(base_channel * channel_ratio * 2 * 2)\n",
    "        # 9~12 stage\n",
    "        init_stage = fin_stage  # 9\n",
    "        fin_stage = fin_stage + depth // 3  # 13\n",
    "        for i in range(init_stage, fin_stage):\n",
    "            s = 2 if i == init_stage else 1\n",
    "            in_channel = stage_2_channel if i == init_stage else stage_3_channel\n",
    "            res_conv = True if i == init_stage else False\n",
    "            last_fusion = True if i == depth else False\n",
    "            self.add_module('conv_trans_' + str(i),\n",
    "                    ConvTransBlock(\n",
    "                        in_channel, stage_3_channel, res_conv, s, dw_stride=trans_dw_stride // 4, embed_dim=embed_dim,\n",
    "                        num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                        drop_rate=drop_rate, attn_drop_rate=attn_drop_rate, drop_path_rate=self.trans_dpr[i-1],\n",
    "                        num_med_block=num_med_block, last_fusion=last_fusion\n",
    "                    )\n",
    "            )\n",
    "        self.fin_stage = fin_stage\n",
    "\n",
    "        trunc_normal_(self.cls_token, std=.02)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.constant_(m.weight, 1.)\n",
    "            nn.init.constant_(m.bias, 0.)\n",
    "        elif isinstance(m, nn.GroupNorm):\n",
    "            nn.init.constant_(m.weight, 1.)\n",
    "            nn.init.constant_(m.bias, 0.)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'cls_token'}\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "\n",
    "        # pdb.set_trace()\n",
    "        # stem stage [N, 3, 224, 224] -> [N, 64, 56, 56]\n",
    "        x_base = self.maxpool(self.act1(self.bn1(self.conv1(x))))\n",
    "\n",
    "        # 1 stage\n",
    "        x = self.conv_1(x_base, return_x_2=False)\n",
    "\n",
    "        x_t = self.trans_patch_conv(x_base).flatten(2).transpose(1, 2)\n",
    "        x_t = torch.cat([cls_tokens, x_t], dim=1)\n",
    "        x_t = self.trans_1(x_t)\n",
    "        \n",
    "        # 2 ~ final \n",
    "        for i in range(2, self.fin_stage):\n",
    "            x, x_t = eval('self.conv_trans_' + str(i))(x, x_t)\n",
    "\n",
    "        # conv classification\n",
    "        x_p = self.pooling(x).flatten(1)\n",
    "        conv_cls = self.conv_cls_head(x_p)\n",
    "\n",
    "        # trans classification\n",
    "        x_t = self.trans_norm(x_t)\n",
    "        tran_cls = self.trans_cls_head(x_t[:, 0])\n",
    "\n",
    "        return [conv_cls, tran_cls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Conformer(patch_size=16, channel_ratio=6, embed_dim=576, depth=12,\n",
    "                      num_heads=9, mlp_ratio=4, qkv_bias=True)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001,  weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# def trainVal(model, criterion, optimizer, num_epochs, min_val_loss, train_loader, val_loader, device):\n",
    "#     best_acc = 0.0\n",
    "#     min_loss = min_val_loss\n",
    "\n",
    "#     train_losses = []\n",
    "#     train_accs = []\n",
    "#     val_losses = []\n",
    "#     val_accs = []\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "#         print('-' * 10)\n",
    "#         model.train()  # Set model to training mode\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "\n",
    "#         # Using tqdm for progress tracking\n",
    "#         for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch}', leave=False):\n",
    "#             inputs = inputs.to(device)\n",
    "#             labels = labels.to(device)\n",
    "\n",
    "#             # zero the parameter gradients\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             # forward\n",
    "#             # track history if only in train\n",
    "#             with torch.set_grad_enabled(True):\n",
    "#                 outputs = model(inputs)\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # backward + optimize only if in training phase\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "\n",
    "#             # statistics\n",
    "#             running_loss += loss.item() * inputs.size(0)\n",
    "#             running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "#         epoch_loss = running_loss / len(train_loader.dataset)\n",
    "#         epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "\n",
    "#         train_losses.append(epoch_loss)\n",
    "#         train_accs.append(epoch_acc)\n",
    "#         print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()  # Set model to evaluate mode\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "\n",
    "#         for inputs, labels in val_loader:\n",
    "#             inputs = inputs.to(device)\n",
    "#             labels = labels.to(device)\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 outputs = model(inputs)\n",
    "#                 if isinstance(outputs, list):\n",
    "#                     outputs = outputs[0] \n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#             running_loss += loss.item() * inputs.size(0)\n",
    "#             running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "#         epoch_loss = running_loss / len(val_loader.dataset)\n",
    "#         epoch_acc = running_corrects.double() / len(val_loader.dataset)\n",
    "\n",
    "#         val_losses.append(epoch_loss)\n",
    "#         val_accs.append(epoch_acc)\n",
    "#         print(f'Val Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "#         # Update the learning rate\n",
    "#         # scheduler.step()  # Uncomment if using a learning rate scheduler\n",
    "\n",
    "#         # Save the model if it has the best validation accuracy so far\n",
    "#         # if epoch_acc > best_acc:\n",
    "#         #     best_acc = epoch_acc\n",
    "#         #     state = {\n",
    "#         #         'epoch': epoch + 1,\n",
    "#         #         'state_dict': model.state_dict(),\n",
    "#         #         'optimizer': optimizer.state_dict(),\n",
    "#         #         'min_loss': epoch_loss\n",
    "#         #     }\n",
    "#         # torch.save(state, 'weight/cvit_deepfake_detection_v2.pth')\n",
    "\n",
    "#     return train_losses, train_accs, val_losses, val_accs, min_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def trainVal(model, criterion, optimizer, num_epochs, min_val_loss, train_loader, val_loader, device):\n",
    "    best_acc = 0.0\n",
    "    min_loss = min_val_loss\n",
    "\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Using tqdm for progress tracking\n",
    "        for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch}', leave=False):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                if isinstance(outputs, list):\n",
    "                    loss_list = [criterion(o, labels) / len(outputs) for o in outputs]\n",
    "                    loss = sum(loss_list)\n",
    "                    preds = torch.max(outputs[0] + outputs[1], 1)[1]\n",
    "                else:\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accs.append(epoch_acc)\n",
    "        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  # Set model to evaluate mode\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                if isinstance(outputs, list):\n",
    "                    loss_list = [criterion(o, labels) / len(outputs) for o in outputs]\n",
    "                    loss = sum(loss_list)\n",
    "                    preds = torch.max(outputs[0] + outputs[1], 1)[1]\n",
    "                else:\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(val_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(val_loader.dataset)\n",
    "\n",
    "        val_losses.append(epoch_loss)\n",
    "        val_accs.append(epoch_acc)\n",
    "        print(f'Val Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        # Update the learning rate\n",
    "        # scheduler.step()  # Uncomment if using a learning rate scheduler\n",
    "\n",
    "        # Save the model if it has the best validation accuracy so far\n",
    "        # if epoch_acc > best_acc:\n",
    "        #     best_acc = epoch_acc\n",
    "        #     state = {\n",
    "        #         'epoch': epoch + 1,\n",
    "        #         'state_dict': model.state_dict(),\n",
    "        #         'optimizer': optimizer.state_dict(),\n",
    "        #         'min_loss': epoch_loss\n",
    "        #     }\n",
    "        # torch.save(state, 'weight/cvit_deepfake_detection_v2.pth')\n",
    "\n",
    "    return train_losses, train_accs, val_losses, val_accs, min_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4422 Acc: 0.8902\n",
      "Val Loss: 0.1909 Acc: 0.9666\n",
      "Epoch 1/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1753 Acc: 0.9647\n",
      "Val Loss: 0.1189 Acc: 0.9740\n",
      "Epoch 2/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1165 Acc: 0.9755\n",
      "Val Loss: 0.1028 Acc: 0.9788\n",
      "Epoch 3/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0969 Acc: 0.9795\n",
      "Val Loss: 0.0412 Acc: 0.9898\n",
      "Epoch 4/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0870 Acc: 0.9809\n",
      "Val Loss: 0.0490 Acc: 0.9887\n",
      "Epoch 5/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0801 Acc: 0.9821\n",
      "Val Loss: 0.0562 Acc: 0.9872\n",
      "Epoch 6/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0752 Acc: 0.9827\n",
      "Val Loss: 0.0433 Acc: 0.9876\n",
      "Epoch 7/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0730 Acc: 0.9832\n",
      "Val Loss: 0.0453 Acc: 0.9884\n",
      "Epoch 8/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0685 Acc: 0.9842\n",
      "Val Loss: 0.0501 Acc: 0.9879\n",
      "Epoch 9/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0679 Acc: 0.9837\n",
      "Val Loss: 0.0917 Acc: 0.9750\n",
      "Epoch 10/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0653 Acc: 0.9842\n",
      "Val Loss: 0.0405 Acc: 0.9895\n",
      "Epoch 11/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0637 Acc: 0.9849\n",
      "Val Loss: 0.0504 Acc: 0.9873\n",
      "Epoch 12/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0634 Acc: 0.9847\n",
      "Val Loss: 0.0443 Acc: 0.9881\n",
      "Epoch 13/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0618 Acc: 0.9850\n",
      "Val Loss: 0.0381 Acc: 0.9901\n",
      "Epoch 14/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0603 Acc: 0.9852\n",
      "Val Loss: 0.0379 Acc: 0.9914\n",
      "Epoch 15/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0614 Acc: 0.9849\n"
     ]
    }
   ],
   "source": [
    "# Define the initial minimum validation loss\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "# Call the training function with the appropriate data loaders\n",
    "train_losses, train_accs, val_losses, val_accs, min_loss = trainVal(\n",
    "    model, criterion, optimizer, num_epochs, min_val_loss, train_loader, val_loader, device\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graspenv",
   "language": "python",
   "name": "graspenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
