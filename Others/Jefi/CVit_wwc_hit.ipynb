{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OZoVbLkg-tdT",
    "outputId": "c25eb1e9-a3d5-4e78-a6cd-f4ac43262b5d"
   },
   "outputs": [],
   "source": [
    "#!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "L0WlakOl-iBR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6357/3799284888.py:14: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from einops import rearrange\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler,autocast\n",
    "import torch.optim as optim\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "gJ0lF8vF-0zF",
    "outputId": "f6a0053c-328f-4df9-8ad0-dabd90c69ac0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZVw0tR92-0wO",
    "outputId": "6ff12ed7-e68b-4101-c310-c695fc664afd"
   },
   "outputs": [],
   "source": [
    "root_path = r\"/home/srikanth/Dataset/Hit-GPRec-merged\"\n",
    "dataset_path = os.listdir(root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBFP8RvPpdRH"
   },
   "source": [
    "DATASET AND DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = []\n",
    "for item in dataset_path:\n",
    "    #print(item)\n",
    "    all_classes = os.listdir(root_path + '/' +item)\n",
    "    for top_object in all_classes:\n",
    "        sub_objects = os.listdir(root_path  + '/' +item + '/' +top_object)\n",
    "        for sub_object in sub_objects:\n",
    "            class_labels.append((item,str(root_path + '/' +item + '/' +top_object + '/' +sub_object)))\n",
    "            \n",
    "df = pd.DataFrame(data=class_labels, columns=['labels', 'image'])\n",
    "y=list(df['labels'].values)\n",
    "image=df['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eZTClF7u_JLw"
   },
   "outputs": [],
   "source": [
    "# class_labels = []\n",
    "\n",
    "# for item in dataset_path:\n",
    "#     #print(item)\n",
    "#     all_objects = os.listdir(root_path + '/' +item)\n",
    "#     for top_object in all_objects:\n",
    "#         sub_objects = os.listdir(root_path  + '/' +item + '/' +top_object)\n",
    "#         for sub_object in sub_objects:\n",
    "#             images = os.listdir(root_path + '/' +item + '/' +top_object + '/' +sub_object)\n",
    "#             for image in images:\n",
    "#                 class_labels.append((item,str(root_path + '/' +item + '/' +top_object + '/' +sub_object +'/' +image)))\n",
    "\n",
    "# df = pd.DataFrame(data=class_labels, columns=['labels', 'image'])\n",
    "# y=list(df['labels'].values)\n",
    "# image=df['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gi6ambS4_JJK"
   },
   "outputs": [],
   "source": [
    "images, y= shuffle(image,y, random_state=1)\n",
    "train_x, test_x, train_y, test_y = train_test_split(images, y, test_size=0.2, random_state=415)\n",
    "test_x = test_x.reset_index(drop=True)\n",
    "train_x = train_x.reset_index(drop=True)\n",
    "test_x, val_x, test_y, val_y = train_test_split(test_x,test_y, test_size=0.5, random_state=415)\n",
    "test_x = test_x.reset_index(drop=True)\n",
    "#train_y=list(train_y)\n",
    "train_df=pd.DataFrame({'filepaths':train_x,'labels':train_y})\n",
    "valid_df=pd.DataFrame({'filepaths':val_x,'labels':val_y})\n",
    "test_df=pd.DataFrame({'filepaths':test_x,'labels':test_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qpl5MDcz_JFz"
   },
   "outputs": [],
   "source": [
    "classes=list(train_df['labels'].unique())\n",
    "class_count=len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lbFGfiwo_JC5",
    "outputId": "2e4ab017-93c8-4c05-f8de-c352b4e41535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spherical': 0, 'tripod': 1, 'lateral': 2, 'cylindrical': 3}\n",
      "{0: 'spherical', 1: 'tripod', 2: 'lateral', 3: 'cylindrical'}\n"
     ]
    }
   ],
   "source": [
    "labels = df['labels'].unique()\n",
    "num_labels = len(labels)\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = i\n",
    "    id2label[i] = label\n",
    "\n",
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ho0xkID4_I_x"
   },
   "outputs": [],
   "source": [
    "class ImageDataset():\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((63, 63), antialias=True),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                             std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "        self.label_mapping = label2id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def get_images(self, idx):\n",
    "        return self.transform(Image.open(self.df.iloc[idx]['filepaths']))\n",
    "\n",
    "    def get_labels(self, idx):\n",
    "        label = self.df.iloc[idx]['labels']\n",
    "        return torch.tensor(self.label_mapping[label], dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        train_images = self.get_images(idx)\n",
    "        train_labels = self.get_labels(idx)\n",
    "\n",
    "        return train_images, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_V2YPqeM_I8p"
   },
   "outputs": [],
   "source": [
    "# Create dataset objects\n",
    "train_dataset = ImageDataset(train_df, transform=transforms)\n",
    "val_dataset = ImageDataset(valid_df, transform=transforms)\n",
    "test_dataset = ImageDataset(test_df, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bmKfee-4_yaC"
   },
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndwvEr7Epu13"
   },
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "C9qjgbSp9V1O"
   },
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(x, **kwargs) + x\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads=8):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.scale = dim ** -0.5\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, dim * 3, bias=False)\n",
    "        self.to_out = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        qkv = self.to_qkv(x)\n",
    "        q, k, v = rearrange(qkv, 'b n (qkv h d) -> qkv b h n d', qkv=3, h=h)\n",
    "\n",
    "        dots = torch.einsum('bhid,bhjd->bhij', q, k) * self.scale\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = F.pad(mask.flatten(1), (1, 0), value = True)\n",
    "            assert mask.shape[-1] == dots.shape[-1], 'mask has incorrect dimensions'\n",
    "            mask = mask[:, None, :] * mask[:, :, None]\n",
    "            dots.masked_fill_(~mask, float('-inf'))\n",
    "            del mask\n",
    "\n",
    "        attn = dots.softmax(dim=-1)\n",
    "\n",
    "        out = torch.einsum('bhij,bhjd->bhid', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        out =  self.to_out(out)\n",
    "        return out\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, mlp_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Residual(PreNorm(dim, Attention(dim, heads = heads))),\n",
    "                Residual(PreNorm(dim, FeedForward(dim, mlp_dim)))\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x, mask=mask)\n",
    "            x = ff(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IkPxisdj-e6S"
   },
   "outputs": [],
   "source": [
    "class CViT(nn.Module):\n",
    "    def __init__(self, image_size=63, patch_size=7, num_classes=4, channels=512,\n",
    "                 dim=1024, depth=6, heads=8, mlp_dim=2048):\n",
    "        super().__init__()\n",
    "        assert image_size % patch_size == 0, 'image dimensions must be divisible by the patch size'\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "\n",
    "        patch_dim = 512 * patch_size ** 2\n",
    "\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(num_patches+1, 1, dim))\n",
    "        self.patch_to_embedding = nn.Linear(patch_dim, dim)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.transformer = Transformer(dim, depth, heads, mlp_dim)\n",
    "\n",
    "        self.to_cls_token = nn.Identity()\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.Linear(dim, mlp_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img, mask=None):\n",
    "        p = self.patch_size\n",
    "        x = self.features(img)\n",
    "        y = rearrange(x, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = p, p2 = p)\n",
    "        y = self.patch_to_embedding(y)\n",
    "        cls_tokens = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "        x = torch.cat((cls_tokens, y), 1)\n",
    "        shape=x.shape[0]\n",
    "        x += self.pos_embedding[0:shape]\n",
    "        x = self.transformer(x, mask)\n",
    "        x = self.to_cls_token(x[:, 0])\n",
    "\n",
    "        return self.mlp_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "R3AKSvW7_yXK"
   },
   "outputs": [],
   "source": [
    "# Initialize your model, optimizer, and loss function\n",
    "model = CViT(image_size=63, patch_size=7, num_classes=4, channels=512,\n",
    "            dim=1024, depth=6, heads=8, mlp_dim=2048)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 40\n",
    "\n",
    "# Initialize the GradScaler for mixed precision training\n",
    "#scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "R13oALfyzokk"
   },
   "outputs": [],
   "source": [
    "def trainVal(model, criterion, optimizer, num_epochs, min_val_loss, train_loader, val_loader, device):\n",
    "    best_acc = 0.0\n",
    "    min_loss = min_val_loss\n",
    "\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        phase_idx = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase_idx % 100 == 0:\n",
    "                print(f'Train Epoch: {epoch} [{phase_idx * len(inputs)}/{len(train_loader.dataset)} ({100. * phase_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "            phase_idx += 1\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accs.append(epoch_acc)\n",
    "        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  # Set model to evaluate mode\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(val_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(val_loader.dataset)\n",
    "\n",
    "        val_losses.append(epoch_loss)\n",
    "        val_accs.append(epoch_acc)\n",
    "        print(f'Val Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        # Update the learning rate\n",
    "        # scheduler.step()  # Uncomment if using a learning rate scheduler\n",
    "\n",
    "        # Save the model if it has the best validation accuracy so far\n",
    "        # if epoch_acc > best_acc:\n",
    "        #     best_acc = epoch_acc\n",
    "        #     state = {\n",
    "        #         'epoch': epoch + 1,\n",
    "        #         'state_dict': model.state_dict(),\n",
    "        #         'optimizer': optimizer.state_dict(),\n",
    "        #         'min_loss': epoch_loss\n",
    "        #     }\n",
    "        #torch.save(state, 'weight/cvit_deepfake_detection_v2.pth')\n",
    "\n",
    "    return train_losses, train_accs, val_losses, val_accs, min_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yh8Uun1l0oet",
    "outputId": "f6ec89e6-1da8-4686-ac64-7612f7bbe155",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srikanth/graspenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/38018 (0%)]\tLoss: 1.415126\n",
      "Train Epoch: 0 [1600/38018 (4%)]\tLoss: 1.100859\n",
      "Train Epoch: 0 [3200/38018 (8%)]\tLoss: 0.546508\n",
      "Train Epoch: 0 [4800/38018 (13%)]\tLoss: 0.982631\n",
      "Train Epoch: 0 [6400/38018 (17%)]\tLoss: 0.672833\n",
      "Train Epoch: 0 [8000/38018 (21%)]\tLoss: 0.542107\n",
      "Train Epoch: 0 [9600/38018 (25%)]\tLoss: 0.679372\n",
      "Train Epoch: 0 [11200/38018 (29%)]\tLoss: 0.177912\n",
      "Train Epoch: 0 [12800/38018 (34%)]\tLoss: 0.772676\n",
      "Train Epoch: 0 [14400/38018 (38%)]\tLoss: 0.528674\n",
      "Train Epoch: 0 [16000/38018 (42%)]\tLoss: 0.329988\n",
      "Train Epoch: 0 [17600/38018 (46%)]\tLoss: 0.586566\n",
      "Train Epoch: 0 [19200/38018 (50%)]\tLoss: 0.642406\n",
      "Train Epoch: 0 [20800/38018 (55%)]\tLoss: 0.273805\n",
      "Train Epoch: 0 [22400/38018 (59%)]\tLoss: 0.202634\n",
      "Train Epoch: 0 [24000/38018 (63%)]\tLoss: 0.579686\n",
      "Train Epoch: 0 [25600/38018 (67%)]\tLoss: 0.255565\n",
      "Train Epoch: 0 [27200/38018 (72%)]\tLoss: 0.490515\n",
      "Train Epoch: 0 [28800/38018 (76%)]\tLoss: 0.276373\n",
      "Train Epoch: 0 [30400/38018 (80%)]\tLoss: 0.336442\n",
      "Train Epoch: 0 [32000/38018 (84%)]\tLoss: 0.278514\n",
      "Train Epoch: 0 [33600/38018 (88%)]\tLoss: 0.296935\n",
      "Train Epoch: 0 [35200/38018 (93%)]\tLoss: 0.319507\n",
      "Train Epoch: 0 [36800/38018 (97%)]\tLoss: 0.670679\n",
      "Train Loss: 0.5454 Acc: 0.7910\n",
      "Val Loss: 0.3125 Acc: 0.8788\n",
      "Epoch 1/39\n",
      "----------\n",
      "Train Epoch: 1 [0/38018 (0%)]\tLoss: 0.209140\n",
      "Train Epoch: 1 [1600/38018 (4%)]\tLoss: 0.324985\n",
      "Train Epoch: 1 [3200/38018 (8%)]\tLoss: 0.451337\n",
      "Train Epoch: 1 [4800/38018 (13%)]\tLoss: 0.304542\n",
      "Train Epoch: 1 [6400/38018 (17%)]\tLoss: 0.373664\n",
      "Train Epoch: 1 [8000/38018 (21%)]\tLoss: 0.048528\n",
      "Train Epoch: 1 [9600/38018 (25%)]\tLoss: 0.921106\n",
      "Train Epoch: 1 [11200/38018 (29%)]\tLoss: 0.420999\n",
      "Train Epoch: 1 [12800/38018 (34%)]\tLoss: 0.407175\n",
      "Train Epoch: 1 [14400/38018 (38%)]\tLoss: 0.260533\n",
      "Train Epoch: 1 [16000/38018 (42%)]\tLoss: 0.277731\n",
      "Train Epoch: 1 [17600/38018 (46%)]\tLoss: 0.127537\n",
      "Train Epoch: 1 [19200/38018 (50%)]\tLoss: 0.261192\n",
      "Train Epoch: 1 [20800/38018 (55%)]\tLoss: 0.122345\n",
      "Train Epoch: 1 [22400/38018 (59%)]\tLoss: 0.122115\n",
      "Train Epoch: 1 [24000/38018 (63%)]\tLoss: 0.051396\n",
      "Train Epoch: 1 [25600/38018 (67%)]\tLoss: 0.421113\n",
      "Train Epoch: 1 [27200/38018 (72%)]\tLoss: 0.170744\n",
      "Train Epoch: 1 [28800/38018 (76%)]\tLoss: 0.380262\n",
      "Train Epoch: 1 [30400/38018 (80%)]\tLoss: 0.459580\n",
      "Train Epoch: 1 [32000/38018 (84%)]\tLoss: 0.190883\n",
      "Train Epoch: 1 [33600/38018 (88%)]\tLoss: 0.147994\n",
      "Train Epoch: 1 [35200/38018 (93%)]\tLoss: 0.149681\n",
      "Train Epoch: 1 [36800/38018 (97%)]\tLoss: 0.091649\n",
      "Train Loss: 0.2765 Acc: 0.8958\n",
      "Val Loss: 0.2176 Acc: 0.9211\n",
      "Epoch 2/39\n",
      "----------\n",
      "Train Epoch: 2 [0/38018 (0%)]\tLoss: 0.012965\n",
      "Train Epoch: 2 [1600/38018 (4%)]\tLoss: 0.552928\n",
      "Train Epoch: 2 [3200/38018 (8%)]\tLoss: 0.113611\n",
      "Train Epoch: 2 [4800/38018 (13%)]\tLoss: 1.019367\n",
      "Train Epoch: 2 [6400/38018 (17%)]\tLoss: 0.037531\n",
      "Train Epoch: 2 [8000/38018 (21%)]\tLoss: 0.130138\n",
      "Train Epoch: 2 [9600/38018 (25%)]\tLoss: 0.140875\n",
      "Train Epoch: 2 [11200/38018 (29%)]\tLoss: 0.095079\n",
      "Train Epoch: 2 [12800/38018 (34%)]\tLoss: 0.043882\n",
      "Train Epoch: 2 [14400/38018 (38%)]\tLoss: 0.019261\n",
      "Train Epoch: 2 [16000/38018 (42%)]\tLoss: 0.101837\n",
      "Train Epoch: 2 [17600/38018 (46%)]\tLoss: 0.188032\n",
      "Train Epoch: 2 [19200/38018 (50%)]\tLoss: 0.365491\n",
      "Train Epoch: 2 [20800/38018 (55%)]\tLoss: 0.013338\n",
      "Train Epoch: 2 [22400/38018 (59%)]\tLoss: 0.079222\n",
      "Train Epoch: 2 [24000/38018 (63%)]\tLoss: 0.131210\n",
      "Train Epoch: 2 [25600/38018 (67%)]\tLoss: 0.185864\n",
      "Train Epoch: 2 [27200/38018 (72%)]\tLoss: 0.070960\n",
      "Train Epoch: 2 [28800/38018 (76%)]\tLoss: 0.268297\n",
      "Train Epoch: 2 [30400/38018 (80%)]\tLoss: 0.083132\n",
      "Train Epoch: 2 [32000/38018 (84%)]\tLoss: 0.116129\n",
      "Train Epoch: 2 [33600/38018 (88%)]\tLoss: 0.038689\n",
      "Train Epoch: 2 [35200/38018 (93%)]\tLoss: 0.597690\n",
      "Train Epoch: 2 [36800/38018 (97%)]\tLoss: 0.317239\n",
      "Train Loss: 0.1858 Acc: 0.9325\n",
      "Val Loss: 0.1176 Acc: 0.9567\n",
      "Epoch 3/39\n",
      "----------\n",
      "Train Epoch: 3 [0/38018 (0%)]\tLoss: 0.263223\n",
      "Train Epoch: 3 [1600/38018 (4%)]\tLoss: 0.153582\n",
      "Train Epoch: 3 [3200/38018 (8%)]\tLoss: 0.192452\n",
      "Train Epoch: 3 [4800/38018 (13%)]\tLoss: 0.073056\n",
      "Train Epoch: 3 [6400/38018 (17%)]\tLoss: 0.105245\n",
      "Train Epoch: 3 [8000/38018 (21%)]\tLoss: 0.082233\n",
      "Train Epoch: 3 [9600/38018 (25%)]\tLoss: 0.106208\n",
      "Train Epoch: 3 [11200/38018 (29%)]\tLoss: 0.027319\n",
      "Train Epoch: 3 [12800/38018 (34%)]\tLoss: 0.297299\n",
      "Train Epoch: 3 [14400/38018 (38%)]\tLoss: 0.032044\n",
      "Train Epoch: 3 [16000/38018 (42%)]\tLoss: 0.113059\n",
      "Train Epoch: 3 [17600/38018 (46%)]\tLoss: 0.057256\n",
      "Train Epoch: 3 [19200/38018 (50%)]\tLoss: 0.046396\n",
      "Train Epoch: 3 [20800/38018 (55%)]\tLoss: 0.370111\n",
      "Train Epoch: 3 [22400/38018 (59%)]\tLoss: 0.062715\n",
      "Train Epoch: 3 [24000/38018 (63%)]\tLoss: 0.528423\n",
      "Train Epoch: 3 [25600/38018 (67%)]\tLoss: 0.029963\n",
      "Train Epoch: 3 [27200/38018 (72%)]\tLoss: 0.030879\n",
      "Train Epoch: 3 [28800/38018 (76%)]\tLoss: 0.063495\n",
      "Train Epoch: 3 [30400/38018 (80%)]\tLoss: 0.245813\n",
      "Train Epoch: 3 [32000/38018 (84%)]\tLoss: 0.194244\n",
      "Train Epoch: 3 [33600/38018 (88%)]\tLoss: 0.557457\n",
      "Train Epoch: 3 [35200/38018 (93%)]\tLoss: 0.154694\n",
      "Train Epoch: 3 [36800/38018 (97%)]\tLoss: 0.650943\n",
      "Train Loss: 0.1919 Acc: 0.9313\n",
      "Val Loss: 0.4302 Acc: 0.8447\n",
      "Epoch 4/39\n",
      "----------\n",
      "Train Epoch: 4 [0/38018 (0%)]\tLoss: 0.317238\n",
      "Train Epoch: 4 [1600/38018 (4%)]\tLoss: 0.368093\n",
      "Train Epoch: 4 [3200/38018 (8%)]\tLoss: 0.250150\n",
      "Train Epoch: 4 [4800/38018 (13%)]\tLoss: 0.130926\n",
      "Train Epoch: 4 [6400/38018 (17%)]\tLoss: 0.344125\n",
      "Train Epoch: 4 [8000/38018 (21%)]\tLoss: 0.323130\n",
      "Train Epoch: 4 [9600/38018 (25%)]\tLoss: 0.169620\n",
      "Train Epoch: 4 [11200/38018 (29%)]\tLoss: 0.244809\n",
      "Train Epoch: 4 [12800/38018 (34%)]\tLoss: 0.085335\n",
      "Train Epoch: 4 [14400/38018 (38%)]\tLoss: 0.488927\n",
      "Train Epoch: 4 [16000/38018 (42%)]\tLoss: 0.612316\n",
      "Train Epoch: 4 [17600/38018 (46%)]\tLoss: 0.078419\n",
      "Train Epoch: 4 [19200/38018 (50%)]\tLoss: 0.048533\n",
      "Train Epoch: 4 [20800/38018 (55%)]\tLoss: 0.120019\n",
      "Train Epoch: 4 [22400/38018 (59%)]\tLoss: 0.065069\n",
      "Train Epoch: 4 [24000/38018 (63%)]\tLoss: 0.034719\n",
      "Train Epoch: 4 [25600/38018 (67%)]\tLoss: 0.037823\n",
      "Train Epoch: 4 [27200/38018 (72%)]\tLoss: 0.063622\n",
      "Train Epoch: 4 [28800/38018 (76%)]\tLoss: 0.023955\n",
      "Train Epoch: 4 [30400/38018 (80%)]\tLoss: 0.049048\n",
      "Train Epoch: 4 [32000/38018 (84%)]\tLoss: 0.025678\n",
      "Train Epoch: 4 [33600/38018 (88%)]\tLoss: 0.294768\n",
      "Train Epoch: 4 [35200/38018 (93%)]\tLoss: 0.129863\n",
      "Train Epoch: 4 [36800/38018 (97%)]\tLoss: 0.092512\n",
      "Train Loss: 0.1654 Acc: 0.9393\n",
      "Val Loss: 0.0722 Acc: 0.9748\n",
      "Epoch 5/39\n",
      "----------\n",
      "Train Epoch: 5 [0/38018 (0%)]\tLoss: 0.195091\n",
      "Train Epoch: 5 [1600/38018 (4%)]\tLoss: 0.006661\n",
      "Train Epoch: 5 [3200/38018 (8%)]\tLoss: 0.422350\n",
      "Train Epoch: 5 [4800/38018 (13%)]\tLoss: 0.008996\n",
      "Train Epoch: 5 [6400/38018 (17%)]\tLoss: 0.170841\n",
      "Train Epoch: 5 [8000/38018 (21%)]\tLoss: 0.229534\n",
      "Train Epoch: 5 [9600/38018 (25%)]\tLoss: 0.167548\n",
      "Train Epoch: 5 [11200/38018 (29%)]\tLoss: 0.114433\n",
      "Train Epoch: 5 [12800/38018 (34%)]\tLoss: 0.057125\n",
      "Train Epoch: 5 [14400/38018 (38%)]\tLoss: 0.161420\n",
      "Train Epoch: 5 [16000/38018 (42%)]\tLoss: 0.039959\n",
      "Train Epoch: 5 [17600/38018 (46%)]\tLoss: 0.432043\n",
      "Train Epoch: 5 [19200/38018 (50%)]\tLoss: 0.040990\n",
      "Train Epoch: 5 [20800/38018 (55%)]\tLoss: 0.146605\n",
      "Train Epoch: 5 [22400/38018 (59%)]\tLoss: 0.001793\n",
      "Train Epoch: 5 [24000/38018 (63%)]\tLoss: 0.059420\n",
      "Train Epoch: 5 [25600/38018 (67%)]\tLoss: 0.055666\n",
      "Train Epoch: 5 [27200/38018 (72%)]\tLoss: 0.014463\n",
      "Train Epoch: 5 [28800/38018 (76%)]\tLoss: 0.118923\n",
      "Train Epoch: 5 [30400/38018 (80%)]\tLoss: 0.017121\n",
      "Train Epoch: 5 [32000/38018 (84%)]\tLoss: 0.083246\n",
      "Train Epoch: 5 [33600/38018 (88%)]\tLoss: 0.009159\n",
      "Train Epoch: 5 [35200/38018 (93%)]\tLoss: 0.068113\n",
      "Train Epoch: 5 [36800/38018 (97%)]\tLoss: 0.039722\n",
      "Train Loss: 0.0934 Acc: 0.9670\n",
      "Val Loss: 0.0898 Acc: 0.9724\n",
      "Epoch 6/39\n",
      "----------\n",
      "Train Epoch: 6 [0/38018 (0%)]\tLoss: 0.018170\n",
      "Train Epoch: 6 [1600/38018 (4%)]\tLoss: 0.018610\n",
      "Train Epoch: 6 [3200/38018 (8%)]\tLoss: 0.177273\n",
      "Train Epoch: 6 [4800/38018 (13%)]\tLoss: 0.058195\n",
      "Train Epoch: 6 [6400/38018 (17%)]\tLoss: 0.030670\n",
      "Train Epoch: 6 [8000/38018 (21%)]\tLoss: 0.030049\n",
      "Train Epoch: 6 [9600/38018 (25%)]\tLoss: 0.012028\n",
      "Train Epoch: 6 [11200/38018 (29%)]\tLoss: 0.000562\n",
      "Train Epoch: 6 [12800/38018 (34%)]\tLoss: 0.044843\n",
      "Train Epoch: 6 [14400/38018 (38%)]\tLoss: 0.010410\n",
      "Train Epoch: 6 [16000/38018 (42%)]\tLoss: 0.231609\n",
      "Train Epoch: 6 [17600/38018 (46%)]\tLoss: 0.124145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [19200/38018 (50%)]\tLoss: 0.020726\n",
      "Train Epoch: 6 [20800/38018 (55%)]\tLoss: 0.005108\n",
      "Train Epoch: 6 [22400/38018 (59%)]\tLoss: 0.003833\n",
      "Train Epoch: 6 [24000/38018 (63%)]\tLoss: 0.038129\n",
      "Train Epoch: 6 [25600/38018 (67%)]\tLoss: 0.153338\n",
      "Train Epoch: 6 [27200/38018 (72%)]\tLoss: 0.051523\n",
      "Train Epoch: 6 [28800/38018 (76%)]\tLoss: 0.005494\n",
      "Train Epoch: 6 [30400/38018 (80%)]\tLoss: 0.230495\n",
      "Train Epoch: 6 [32000/38018 (84%)]\tLoss: 0.127133\n",
      "Train Epoch: 6 [33600/38018 (88%)]\tLoss: 0.010378\n",
      "Train Epoch: 6 [35200/38018 (93%)]\tLoss: 0.090129\n",
      "Train Epoch: 6 [36800/38018 (97%)]\tLoss: 0.005255\n",
      "Train Loss: 0.0858 Acc: 0.9701\n",
      "Val Loss: 0.0885 Acc: 0.9691\n",
      "Epoch 7/39\n",
      "----------\n",
      "Train Epoch: 7 [0/38018 (0%)]\tLoss: 0.038081\n",
      "Train Epoch: 7 [1600/38018 (4%)]\tLoss: 0.119956\n",
      "Train Epoch: 7 [3200/38018 (8%)]\tLoss: 0.035038\n",
      "Train Epoch: 7 [4800/38018 (13%)]\tLoss: 0.128526\n",
      "Train Epoch: 7 [6400/38018 (17%)]\tLoss: 0.027575\n",
      "Train Epoch: 7 [8000/38018 (21%)]\tLoss: 0.016611\n",
      "Train Epoch: 7 [9600/38018 (25%)]\tLoss: 0.135600\n",
      "Train Epoch: 7 [11200/38018 (29%)]\tLoss: 0.004655\n",
      "Train Epoch: 7 [12800/38018 (34%)]\tLoss: 0.019019\n",
      "Train Epoch: 7 [14400/38018 (38%)]\tLoss: 0.085155\n",
      "Train Epoch: 7 [16000/38018 (42%)]\tLoss: 0.014251\n",
      "Train Epoch: 7 [17600/38018 (46%)]\tLoss: 0.001813\n",
      "Train Epoch: 7 [19200/38018 (50%)]\tLoss: 0.009827\n",
      "Train Epoch: 7 [20800/38018 (55%)]\tLoss: 0.088962\n",
      "Train Epoch: 7 [22400/38018 (59%)]\tLoss: 0.046757\n",
      "Train Epoch: 7 [24000/38018 (63%)]\tLoss: 0.016420\n",
      "Train Epoch: 7 [25600/38018 (67%)]\tLoss: 0.292831\n",
      "Train Epoch: 7 [27200/38018 (72%)]\tLoss: 0.003349\n",
      "Train Epoch: 7 [28800/38018 (76%)]\tLoss: 0.004294\n",
      "Train Epoch: 7 [30400/38018 (80%)]\tLoss: 0.206652\n",
      "Train Epoch: 7 [32000/38018 (84%)]\tLoss: 0.003824\n",
      "Train Epoch: 7 [33600/38018 (88%)]\tLoss: 0.004620\n",
      "Train Epoch: 7 [35200/38018 (93%)]\tLoss: 0.012123\n",
      "Train Epoch: 7 [36800/38018 (97%)]\tLoss: 0.540428\n",
      "Train Loss: 0.0769 Acc: 0.9730\n",
      "Val Loss: 0.2313 Acc: 0.9411\n",
      "Epoch 8/39\n",
      "----------\n",
      "Train Epoch: 8 [0/38018 (0%)]\tLoss: 0.061086\n",
      "Train Epoch: 8 [1600/38018 (4%)]\tLoss: 0.000819\n",
      "Train Epoch: 8 [3200/38018 (8%)]\tLoss: 0.063296\n",
      "Train Epoch: 8 [4800/38018 (13%)]\tLoss: 0.002293\n",
      "Train Epoch: 8 [6400/38018 (17%)]\tLoss: 0.185605\n",
      "Train Epoch: 8 [8000/38018 (21%)]\tLoss: 0.139151\n",
      "Train Epoch: 8 [9600/38018 (25%)]\tLoss: 0.004399\n",
      "Train Epoch: 8 [11200/38018 (29%)]\tLoss: 0.013204\n",
      "Train Epoch: 8 [12800/38018 (34%)]\tLoss: 0.022327\n",
      "Train Epoch: 8 [14400/38018 (38%)]\tLoss: 0.114708\n",
      "Train Epoch: 8 [16000/38018 (42%)]\tLoss: 0.000427\n",
      "Train Epoch: 8 [17600/38018 (46%)]\tLoss: 0.057258\n",
      "Train Epoch: 8 [19200/38018 (50%)]\tLoss: 0.004762\n",
      "Train Epoch: 8 [20800/38018 (55%)]\tLoss: 0.022176\n",
      "Train Epoch: 8 [22400/38018 (59%)]\tLoss: 0.007720\n",
      "Train Epoch: 8 [24000/38018 (63%)]\tLoss: 0.034047\n",
      "Train Epoch: 8 [25600/38018 (67%)]\tLoss: 0.033775\n",
      "Train Epoch: 8 [27200/38018 (72%)]\tLoss: 0.003137\n",
      "Train Epoch: 8 [28800/38018 (76%)]\tLoss: 0.025165\n",
      "Train Epoch: 8 [30400/38018 (80%)]\tLoss: 0.013748\n",
      "Train Epoch: 8 [32000/38018 (84%)]\tLoss: 0.290133\n",
      "Train Epoch: 8 [33600/38018 (88%)]\tLoss: 0.020431\n",
      "Train Epoch: 8 [35200/38018 (93%)]\tLoss: 0.070531\n",
      "Train Epoch: 8 [36800/38018 (97%)]\tLoss: 0.098892\n",
      "Train Loss: 0.0676 Acc: 0.9775\n",
      "Val Loss: 0.0713 Acc: 0.9743\n",
      "Epoch 9/39\n",
      "----------\n",
      "Train Epoch: 9 [0/38018 (0%)]\tLoss: 0.055565\n",
      "Train Epoch: 9 [1600/38018 (4%)]\tLoss: 0.009026\n",
      "Train Epoch: 9 [3200/38018 (8%)]\tLoss: 0.010915\n",
      "Train Epoch: 9 [4800/38018 (13%)]\tLoss: 0.014610\n",
      "Train Epoch: 9 [6400/38018 (17%)]\tLoss: 0.000177\n",
      "Train Epoch: 9 [8000/38018 (21%)]\tLoss: 0.014179\n",
      "Train Epoch: 9 [9600/38018 (25%)]\tLoss: 0.260786\n",
      "Train Epoch: 9 [11200/38018 (29%)]\tLoss: 0.019224\n",
      "Train Epoch: 9 [12800/38018 (34%)]\tLoss: 0.045994\n",
      "Train Epoch: 9 [14400/38018 (38%)]\tLoss: 0.064284\n",
      "Train Epoch: 9 [16000/38018 (42%)]\tLoss: 0.077880\n",
      "Train Epoch: 9 [17600/38018 (46%)]\tLoss: 0.373531\n",
      "Train Epoch: 9 [19200/38018 (50%)]\tLoss: 0.044389\n",
      "Train Epoch: 9 [20800/38018 (55%)]\tLoss: 0.015631\n",
      "Train Epoch: 9 [22400/38018 (59%)]\tLoss: 0.028303\n",
      "Train Epoch: 9 [24000/38018 (63%)]\tLoss: 0.002057\n",
      "Train Epoch: 9 [25600/38018 (67%)]\tLoss: 0.003594\n",
      "Train Epoch: 9 [27200/38018 (72%)]\tLoss: 0.161013\n",
      "Train Epoch: 9 [28800/38018 (76%)]\tLoss: 0.012193\n",
      "Train Epoch: 9 [30400/38018 (80%)]\tLoss: 0.006091\n",
      "Train Epoch: 9 [32000/38018 (84%)]\tLoss: 0.002185\n",
      "Train Epoch: 9 [33600/38018 (88%)]\tLoss: 0.000489\n",
      "Train Epoch: 9 [35200/38018 (93%)]\tLoss: 0.128467\n",
      "Train Epoch: 9 [36800/38018 (97%)]\tLoss: 0.001595\n",
      "Train Loss: 0.0637 Acc: 0.9780\n",
      "Val Loss: 0.0468 Acc: 0.9846\n",
      "Epoch 10/39\n",
      "----------\n",
      "Train Epoch: 10 [0/38018 (0%)]\tLoss: 0.001598\n",
      "Train Epoch: 10 [1600/38018 (4%)]\tLoss: 0.000794\n",
      "Train Epoch: 10 [3200/38018 (8%)]\tLoss: 0.084590\n",
      "Train Epoch: 10 [4800/38018 (13%)]\tLoss: 0.000056\n",
      "Train Epoch: 10 [6400/38018 (17%)]\tLoss: 0.059266\n",
      "Train Epoch: 10 [8000/38018 (21%)]\tLoss: 0.017111\n",
      "Train Epoch: 10 [9600/38018 (25%)]\tLoss: 0.006687\n",
      "Train Epoch: 10 [11200/38018 (29%)]\tLoss: 0.001863\n",
      "Train Epoch: 10 [12800/38018 (34%)]\tLoss: 0.086230\n",
      "Train Epoch: 10 [14400/38018 (38%)]\tLoss: 0.247177\n",
      "Train Epoch: 10 [16000/38018 (42%)]\tLoss: 0.081255\n",
      "Train Epoch: 10 [17600/38018 (46%)]\tLoss: 0.006637\n",
      "Train Epoch: 10 [19200/38018 (50%)]\tLoss: 0.042334\n",
      "Train Epoch: 10 [20800/38018 (55%)]\tLoss: 0.033731\n",
      "Train Epoch: 10 [22400/38018 (59%)]\tLoss: 0.015248\n",
      "Train Epoch: 10 [24000/38018 (63%)]\tLoss: 0.002835\n",
      "Train Epoch: 10 [25600/38018 (67%)]\tLoss: 0.001454\n",
      "Train Epoch: 10 [27200/38018 (72%)]\tLoss: 0.007420\n",
      "Train Epoch: 10 [28800/38018 (76%)]\tLoss: 0.041653\n",
      "Train Epoch: 10 [30400/38018 (80%)]\tLoss: 0.009825\n",
      "Train Epoch: 10 [32000/38018 (84%)]\tLoss: 0.002605\n",
      "Train Epoch: 10 [33600/38018 (88%)]\tLoss: 0.105040\n",
      "Train Epoch: 10 [35200/38018 (93%)]\tLoss: 0.241987\n",
      "Train Epoch: 10 [36800/38018 (97%)]\tLoss: 0.001684\n",
      "Train Loss: 0.0534 Acc: 0.9819\n",
      "Val Loss: 0.0822 Acc: 0.9722\n",
      "Epoch 11/39\n",
      "----------\n",
      "Train Epoch: 11 [0/38018 (0%)]\tLoss: 0.041040\n",
      "Train Epoch: 11 [1600/38018 (4%)]\tLoss: 0.169696\n",
      "Train Epoch: 11 [3200/38018 (8%)]\tLoss: 0.008471\n",
      "Train Epoch: 11 [4800/38018 (13%)]\tLoss: 0.011594\n",
      "Train Epoch: 11 [6400/38018 (17%)]\tLoss: 0.002232\n",
      "Train Epoch: 11 [8000/38018 (21%)]\tLoss: 0.166861\n",
      "Train Epoch: 11 [9600/38018 (25%)]\tLoss: 0.065219\n",
      "Train Epoch: 11 [11200/38018 (29%)]\tLoss: 0.015950\n",
      "Train Epoch: 11 [12800/38018 (34%)]\tLoss: 0.121653\n",
      "Train Epoch: 11 [14400/38018 (38%)]\tLoss: 0.000900\n",
      "Train Epoch: 11 [16000/38018 (42%)]\tLoss: 0.004825\n",
      "Train Epoch: 11 [17600/38018 (46%)]\tLoss: 0.000946\n",
      "Train Epoch: 11 [19200/38018 (50%)]\tLoss: 0.025175\n",
      "Train Epoch: 11 [20800/38018 (55%)]\tLoss: 0.115478\n",
      "Train Epoch: 11 [22400/38018 (59%)]\tLoss: 0.167361\n",
      "Train Epoch: 11 [24000/38018 (63%)]\tLoss: 0.085490\n",
      "Train Epoch: 11 [25600/38018 (67%)]\tLoss: 0.045186\n",
      "Train Epoch: 11 [27200/38018 (72%)]\tLoss: 0.005033\n",
      "Train Epoch: 11 [28800/38018 (76%)]\tLoss: 0.004388\n",
      "Train Epoch: 11 [30400/38018 (80%)]\tLoss: 0.162981\n",
      "Train Epoch: 11 [32000/38018 (84%)]\tLoss: 0.004472\n",
      "Train Epoch: 11 [33600/38018 (88%)]\tLoss: 0.174280\n",
      "Train Epoch: 11 [35200/38018 (93%)]\tLoss: 0.000091\n",
      "Train Epoch: 11 [36800/38018 (97%)]\tLoss: 0.000310\n",
      "Train Loss: 0.0543 Acc: 0.9816\n",
      "Val Loss: 0.0236 Acc: 0.9935\n",
      "Epoch 12/39\n",
      "----------\n",
      "Train Epoch: 12 [0/38018 (0%)]\tLoss: 0.005815\n",
      "Train Epoch: 12 [1600/38018 (4%)]\tLoss: 0.033567\n",
      "Train Epoch: 12 [3200/38018 (8%)]\tLoss: 0.000679\n",
      "Train Epoch: 12 [4800/38018 (13%)]\tLoss: 0.042280\n",
      "Train Epoch: 12 [6400/38018 (17%)]\tLoss: 0.022801\n",
      "Train Epoch: 12 [8000/38018 (21%)]\tLoss: 0.001216\n",
      "Train Epoch: 12 [9600/38018 (25%)]\tLoss: 0.003092\n",
      "Train Epoch: 12 [11200/38018 (29%)]\tLoss: 0.015207\n",
      "Train Epoch: 12 [12800/38018 (34%)]\tLoss: 0.153240\n",
      "Train Epoch: 12 [14400/38018 (38%)]\tLoss: 0.000496\n",
      "Train Epoch: 12 [16000/38018 (42%)]\tLoss: 0.096742\n",
      "Train Epoch: 12 [17600/38018 (46%)]\tLoss: 0.003425\n",
      "Train Epoch: 12 [19200/38018 (50%)]\tLoss: 0.002242\n",
      "Train Epoch: 12 [20800/38018 (55%)]\tLoss: 0.146716\n",
      "Train Epoch: 12 [22400/38018 (59%)]\tLoss: 0.002626\n",
      "Train Epoch: 12 [24000/38018 (63%)]\tLoss: 0.000376\n",
      "Train Epoch: 12 [25600/38018 (67%)]\tLoss: 0.005228\n",
      "Train Epoch: 12 [27200/38018 (72%)]\tLoss: 0.035608\n",
      "Train Epoch: 12 [28800/38018 (76%)]\tLoss: 0.048908\n",
      "Train Epoch: 12 [30400/38018 (80%)]\tLoss: 0.051959\n",
      "Train Epoch: 12 [32000/38018 (84%)]\tLoss: 0.013930\n",
      "Train Epoch: 12 [33600/38018 (88%)]\tLoss: 0.000671\n",
      "Train Epoch: 12 [35200/38018 (93%)]\tLoss: 0.016132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [36800/38018 (97%)]\tLoss: 0.097371\n",
      "Train Loss: 0.0447 Acc: 0.9854\n",
      "Val Loss: 0.0365 Acc: 0.9886\n",
      "Epoch 13/39\n",
      "----------\n",
      "Train Epoch: 13 [0/38018 (0%)]\tLoss: 0.000060\n",
      "Train Epoch: 13 [1600/38018 (4%)]\tLoss: 0.003722\n",
      "Train Epoch: 13 [3200/38018 (8%)]\tLoss: 0.012852\n",
      "Train Epoch: 13 [4800/38018 (13%)]\tLoss: 0.000755\n",
      "Train Epoch: 13 [6400/38018 (17%)]\tLoss: 0.021732\n",
      "Train Epoch: 13 [8000/38018 (21%)]\tLoss: 0.101001\n",
      "Train Epoch: 13 [9600/38018 (25%)]\tLoss: 0.051002\n",
      "Train Epoch: 13 [11200/38018 (29%)]\tLoss: 0.437220\n",
      "Train Epoch: 13 [12800/38018 (34%)]\tLoss: 0.001137\n",
      "Train Epoch: 13 [14400/38018 (38%)]\tLoss: 0.001415\n",
      "Train Epoch: 13 [16000/38018 (42%)]\tLoss: 0.008020\n",
      "Train Epoch: 13 [17600/38018 (46%)]\tLoss: 0.052225\n",
      "Train Epoch: 13 [19200/38018 (50%)]\tLoss: 0.042907\n",
      "Train Epoch: 13 [20800/38018 (55%)]\tLoss: 0.000035\n",
      "Train Epoch: 13 [22400/38018 (59%)]\tLoss: 0.001288\n",
      "Train Epoch: 13 [24000/38018 (63%)]\tLoss: 0.000495\n",
      "Train Epoch: 13 [25600/38018 (67%)]\tLoss: 0.250450\n",
      "Train Epoch: 13 [27200/38018 (72%)]\tLoss: 0.144134\n",
      "Train Epoch: 13 [28800/38018 (76%)]\tLoss: 0.001854\n",
      "Train Epoch: 13 [30400/38018 (80%)]\tLoss: 0.000555\n",
      "Train Epoch: 13 [32000/38018 (84%)]\tLoss: 0.032603\n",
      "Train Epoch: 13 [33600/38018 (88%)]\tLoss: 0.501735\n",
      "Train Epoch: 13 [35200/38018 (93%)]\tLoss: 0.009974\n",
      "Train Epoch: 13 [36800/38018 (97%)]\tLoss: 0.005119\n",
      "Train Loss: 0.0395 Acc: 0.9871\n",
      "Val Loss: 0.0260 Acc: 0.9905\n",
      "Epoch 14/39\n",
      "----------\n",
      "Train Epoch: 14 [0/38018 (0%)]\tLoss: 0.000774\n",
      "Train Epoch: 14 [1600/38018 (4%)]\tLoss: 0.220832\n",
      "Train Epoch: 14 [3200/38018 (8%)]\tLoss: 0.002927\n",
      "Train Epoch: 14 [4800/38018 (13%)]\tLoss: 0.010313\n",
      "Train Epoch: 14 [6400/38018 (17%)]\tLoss: 0.006519\n",
      "Train Epoch: 14 [8000/38018 (21%)]\tLoss: 0.000190\n",
      "Train Epoch: 14 [9600/38018 (25%)]\tLoss: 0.006139\n",
      "Train Epoch: 14 [11200/38018 (29%)]\tLoss: 0.008556\n",
      "Train Epoch: 14 [12800/38018 (34%)]\tLoss: 0.001129\n",
      "Train Epoch: 14 [14400/38018 (38%)]\tLoss: 0.000330\n",
      "Train Epoch: 14 [16000/38018 (42%)]\tLoss: 0.136499\n",
      "Train Epoch: 14 [17600/38018 (46%)]\tLoss: 0.138648\n",
      "Train Epoch: 14 [19200/38018 (50%)]\tLoss: 0.013771\n",
      "Train Epoch: 14 [20800/38018 (55%)]\tLoss: 0.004665\n",
      "Train Epoch: 14 [22400/38018 (59%)]\tLoss: 0.000084\n",
      "Train Epoch: 14 [24000/38018 (63%)]\tLoss: 0.004486\n",
      "Train Epoch: 14 [25600/38018 (67%)]\tLoss: 0.063146\n",
      "Train Epoch: 14 [27200/38018 (72%)]\tLoss: 0.009515\n",
      "Train Epoch: 14 [28800/38018 (76%)]\tLoss: 0.013770\n",
      "Train Epoch: 14 [30400/38018 (80%)]\tLoss: 0.003211\n",
      "Train Epoch: 14 [32000/38018 (84%)]\tLoss: 0.001090\n",
      "Train Epoch: 14 [33600/38018 (88%)]\tLoss: 0.083265\n",
      "Train Epoch: 14 [35200/38018 (93%)]\tLoss: 0.067255\n",
      "Train Epoch: 14 [36800/38018 (97%)]\tLoss: 0.017745\n",
      "Train Loss: 0.0345 Acc: 0.9880\n",
      "Val Loss: 0.0824 Acc: 0.9748\n",
      "Epoch 15/39\n",
      "----------\n",
      "Train Epoch: 15 [0/38018 (0%)]\tLoss: 0.009485\n",
      "Train Epoch: 15 [1600/38018 (4%)]\tLoss: 0.011678\n",
      "Train Epoch: 15 [3200/38018 (8%)]\tLoss: 0.008621\n",
      "Train Epoch: 15 [4800/38018 (13%)]\tLoss: 0.007379\n",
      "Train Epoch: 15 [6400/38018 (17%)]\tLoss: 0.001982\n",
      "Train Epoch: 15 [8000/38018 (21%)]\tLoss: 0.008386\n",
      "Train Epoch: 15 [9600/38018 (25%)]\tLoss: 0.019157\n",
      "Train Epoch: 15 [11200/38018 (29%)]\tLoss: 0.148904\n",
      "Train Epoch: 15 [12800/38018 (34%)]\tLoss: 0.000123\n",
      "Train Epoch: 15 [14400/38018 (38%)]\tLoss: 0.000316\n",
      "Train Epoch: 15 [16000/38018 (42%)]\tLoss: 0.138565\n",
      "Train Epoch: 15 [17600/38018 (46%)]\tLoss: 0.024231\n",
      "Train Epoch: 15 [19200/38018 (50%)]\tLoss: 0.000152\n",
      "Train Epoch: 15 [20800/38018 (55%)]\tLoss: 0.004010\n",
      "Train Epoch: 15 [22400/38018 (59%)]\tLoss: 0.000718\n",
      "Train Epoch: 15 [24000/38018 (63%)]\tLoss: 0.003044\n",
      "Train Epoch: 15 [25600/38018 (67%)]\tLoss: 0.010245\n",
      "Train Epoch: 15 [27200/38018 (72%)]\tLoss: 0.000141\n",
      "Train Epoch: 15 [28800/38018 (76%)]\tLoss: 0.565138\n",
      "Train Epoch: 15 [30400/38018 (80%)]\tLoss: 0.023192\n",
      "Train Epoch: 15 [32000/38018 (84%)]\tLoss: 0.009064\n",
      "Train Epoch: 15 [33600/38018 (88%)]\tLoss: 0.007560\n",
      "Train Epoch: 15 [35200/38018 (93%)]\tLoss: 0.003595\n",
      "Train Epoch: 15 [36800/38018 (97%)]\tLoss: 0.000636\n",
      "Train Loss: 0.0331 Acc: 0.9892\n",
      "Val Loss: 0.0170 Acc: 0.9962\n",
      "Epoch 16/39\n",
      "----------\n",
      "Train Epoch: 16 [0/38018 (0%)]\tLoss: 0.000221\n",
      "Train Epoch: 16 [1600/38018 (4%)]\tLoss: 0.003991\n",
      "Train Epoch: 16 [3200/38018 (8%)]\tLoss: 0.000904\n",
      "Train Epoch: 16 [4800/38018 (13%)]\tLoss: 0.003249\n",
      "Train Epoch: 16 [6400/38018 (17%)]\tLoss: 0.023044\n",
      "Train Epoch: 16 [8000/38018 (21%)]\tLoss: 0.000131\n",
      "Train Epoch: 16 [9600/38018 (25%)]\tLoss: 0.009014\n",
      "Train Epoch: 16 [11200/38018 (29%)]\tLoss: 0.001231\n",
      "Train Epoch: 16 [12800/38018 (34%)]\tLoss: 0.026343\n",
      "Train Epoch: 16 [14400/38018 (38%)]\tLoss: 0.000404\n",
      "Train Epoch: 16 [16000/38018 (42%)]\tLoss: 0.063059\n",
      "Train Epoch: 16 [17600/38018 (46%)]\tLoss: 0.013322\n",
      "Train Epoch: 16 [19200/38018 (50%)]\tLoss: 0.539702\n",
      "Train Epoch: 16 [20800/38018 (55%)]\tLoss: 0.003417\n",
      "Train Epoch: 16 [22400/38018 (59%)]\tLoss: 0.000278\n",
      "Train Epoch: 16 [24000/38018 (63%)]\tLoss: 0.014631\n",
      "Train Epoch: 16 [25600/38018 (67%)]\tLoss: 0.055388\n",
      "Train Epoch: 16 [27200/38018 (72%)]\tLoss: 0.008334\n",
      "Train Epoch: 16 [28800/38018 (76%)]\tLoss: 0.214491\n",
      "Train Epoch: 16 [30400/38018 (80%)]\tLoss: 0.003292\n",
      "Train Epoch: 16 [32000/38018 (84%)]\tLoss: 0.001457\n",
      "Train Epoch: 16 [33600/38018 (88%)]\tLoss: 0.025228\n",
      "Train Epoch: 16 [35200/38018 (93%)]\tLoss: 0.013494\n",
      "Train Epoch: 16 [36800/38018 (97%)]\tLoss: 0.000285\n",
      "Train Loss: 0.0346 Acc: 0.9888\n",
      "Val Loss: 0.0148 Acc: 0.9956\n",
      "Epoch 17/39\n",
      "----------\n",
      "Train Epoch: 17 [0/38018 (0%)]\tLoss: 0.016006\n",
      "Train Epoch: 17 [1600/38018 (4%)]\tLoss: 0.000268\n",
      "Train Epoch: 17 [3200/38018 (8%)]\tLoss: 0.015750\n",
      "Train Epoch: 17 [4800/38018 (13%)]\tLoss: 0.000333\n",
      "Train Epoch: 17 [6400/38018 (17%)]\tLoss: 0.003245\n",
      "Train Epoch: 17 [8000/38018 (21%)]\tLoss: 0.003017\n",
      "Train Epoch: 17 [9600/38018 (25%)]\tLoss: 0.000359\n",
      "Train Epoch: 17 [11200/38018 (29%)]\tLoss: 0.029428\n",
      "Train Epoch: 17 [12800/38018 (34%)]\tLoss: 0.045139\n",
      "Train Epoch: 17 [14400/38018 (38%)]\tLoss: 0.000315\n",
      "Train Epoch: 17 [16000/38018 (42%)]\tLoss: 0.000029\n",
      "Train Epoch: 17 [17600/38018 (46%)]\tLoss: 0.001219\n",
      "Train Epoch: 17 [19200/38018 (50%)]\tLoss: 0.000990\n",
      "Train Epoch: 17 [20800/38018 (55%)]\tLoss: 0.000123\n",
      "Train Epoch: 17 [22400/38018 (59%)]\tLoss: 0.003192\n",
      "Train Epoch: 17 [24000/38018 (63%)]\tLoss: 0.001134\n",
      "Train Epoch: 17 [25600/38018 (67%)]\tLoss: 0.001215\n",
      "Train Epoch: 17 [27200/38018 (72%)]\tLoss: 0.080868\n",
      "Train Epoch: 17 [28800/38018 (76%)]\tLoss: 0.000179\n",
      "Train Epoch: 17 [30400/38018 (80%)]\tLoss: 0.000913\n",
      "Train Epoch: 17 [32000/38018 (84%)]\tLoss: 0.000207\n",
      "Train Epoch: 17 [33600/38018 (88%)]\tLoss: 0.002745\n",
      "Train Epoch: 17 [35200/38018 (93%)]\tLoss: 0.000150\n",
      "Train Epoch: 17 [36800/38018 (97%)]\tLoss: 0.004918\n",
      "Train Loss: 0.0324 Acc: 0.9896\n",
      "Val Loss: 0.0197 Acc: 0.9947\n",
      "Epoch 18/39\n",
      "----------\n",
      "Train Epoch: 18 [0/38018 (0%)]\tLoss: 0.001178\n",
      "Train Epoch: 18 [1600/38018 (4%)]\tLoss: 0.001224\n",
      "Train Epoch: 18 [3200/38018 (8%)]\tLoss: 0.003820\n",
      "Train Epoch: 18 [4800/38018 (13%)]\tLoss: 0.001843\n",
      "Train Epoch: 18 [6400/38018 (17%)]\tLoss: 0.140620\n",
      "Train Epoch: 18 [8000/38018 (21%)]\tLoss: 0.000164\n",
      "Train Epoch: 18 [9600/38018 (25%)]\tLoss: 0.016110\n",
      "Train Epoch: 18 [11200/38018 (29%)]\tLoss: 0.002166\n",
      "Train Epoch: 18 [12800/38018 (34%)]\tLoss: 0.000233\n",
      "Train Epoch: 18 [14400/38018 (38%)]\tLoss: 0.001315\n",
      "Train Epoch: 18 [16000/38018 (42%)]\tLoss: 0.002081\n",
      "Train Epoch: 18 [17600/38018 (46%)]\tLoss: 0.002179\n",
      "Train Epoch: 18 [19200/38018 (50%)]\tLoss: 0.000426\n",
      "Train Epoch: 18 [20800/38018 (55%)]\tLoss: 0.001241\n",
      "Train Epoch: 18 [22400/38018 (59%)]\tLoss: 0.023406\n",
      "Train Epoch: 18 [24000/38018 (63%)]\tLoss: 0.019233\n",
      "Train Epoch: 18 [25600/38018 (67%)]\tLoss: 0.042843\n",
      "Train Epoch: 18 [27200/38018 (72%)]\tLoss: 0.002646\n",
      "Train Epoch: 18 [28800/38018 (76%)]\tLoss: 0.008159\n",
      "Train Epoch: 18 [30400/38018 (80%)]\tLoss: 0.055645\n",
      "Train Epoch: 18 [32000/38018 (84%)]\tLoss: 0.000930\n",
      "Train Epoch: 18 [33600/38018 (88%)]\tLoss: 0.000134\n",
      "Train Epoch: 18 [35200/38018 (93%)]\tLoss: 0.000333\n",
      "Train Epoch: 18 [36800/38018 (97%)]\tLoss: 0.000740\n",
      "Train Loss: 0.0335 Acc: 0.9903\n",
      "Val Loss: 0.0198 Acc: 0.9941\n",
      "Epoch 19/39\n",
      "----------\n",
      "Train Epoch: 19 [0/38018 (0%)]\tLoss: 0.000208\n",
      "Train Epoch: 19 [1600/38018 (4%)]\tLoss: 0.001107\n",
      "Train Epoch: 19 [3200/38018 (8%)]\tLoss: 0.000150\n",
      "Train Epoch: 19 [4800/38018 (13%)]\tLoss: 0.000311\n",
      "Train Epoch: 19 [6400/38018 (17%)]\tLoss: 0.000236\n",
      "Train Epoch: 19 [8000/38018 (21%)]\tLoss: 0.065571\n",
      "Train Epoch: 19 [9600/38018 (25%)]\tLoss: 0.070774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 [11200/38018 (29%)]\tLoss: 0.002515\n",
      "Train Epoch: 19 [12800/38018 (34%)]\tLoss: 0.003485\n",
      "Train Epoch: 19 [14400/38018 (38%)]\tLoss: 0.000030\n",
      "Train Epoch: 19 [16000/38018 (42%)]\tLoss: 0.000050\n",
      "Train Epoch: 19 [17600/38018 (46%)]\tLoss: 0.000787\n",
      "Train Epoch: 19 [19200/38018 (50%)]\tLoss: 0.001281\n",
      "Train Epoch: 19 [20800/38018 (55%)]\tLoss: 0.013520\n",
      "Train Epoch: 19 [22400/38018 (59%)]\tLoss: 0.000630\n",
      "Train Epoch: 19 [24000/38018 (63%)]\tLoss: 0.000233\n",
      "Train Epoch: 19 [25600/38018 (67%)]\tLoss: 0.018793\n",
      "Train Epoch: 19 [27200/38018 (72%)]\tLoss: 0.000095\n",
      "Train Epoch: 19 [28800/38018 (76%)]\tLoss: 0.040067\n",
      "Train Epoch: 19 [30400/38018 (80%)]\tLoss: 0.188244\n",
      "Train Epoch: 19 [32000/38018 (84%)]\tLoss: 0.001194\n",
      "Train Epoch: 19 [33600/38018 (88%)]\tLoss: 0.190175\n",
      "Train Epoch: 19 [35200/38018 (93%)]\tLoss: 0.000281\n",
      "Train Epoch: 19 [36800/38018 (97%)]\tLoss: 0.002940\n",
      "Train Loss: 0.0279 Acc: 0.9913\n",
      "Val Loss: 0.0446 Acc: 0.9893\n",
      "Epoch 20/39\n",
      "----------\n",
      "Train Epoch: 20 [0/38018 (0%)]\tLoss: 0.000139\n",
      "Train Epoch: 20 [1600/38018 (4%)]\tLoss: 0.364472\n",
      "Train Epoch: 20 [3200/38018 (8%)]\tLoss: 0.000347\n",
      "Train Epoch: 20 [4800/38018 (13%)]\tLoss: 0.013380\n",
      "Train Epoch: 20 [6400/38018 (17%)]\tLoss: 0.001359\n",
      "Train Epoch: 20 [8000/38018 (21%)]\tLoss: 0.010711\n",
      "Train Epoch: 20 [9600/38018 (25%)]\tLoss: 0.004293\n",
      "Train Epoch: 20 [11200/38018 (29%)]\tLoss: 0.000594\n",
      "Train Epoch: 20 [12800/38018 (34%)]\tLoss: 0.001374\n",
      "Train Epoch: 20 [14400/38018 (38%)]\tLoss: 0.000613\n",
      "Train Epoch: 20 [16000/38018 (42%)]\tLoss: 0.000106\n",
      "Train Epoch: 20 [17600/38018 (46%)]\tLoss: 0.000069\n",
      "Train Epoch: 20 [19200/38018 (50%)]\tLoss: 0.000666\n",
      "Train Epoch: 20 [20800/38018 (55%)]\tLoss: 0.000014\n",
      "Train Epoch: 20 [22400/38018 (59%)]\tLoss: 0.000205\n",
      "Train Epoch: 20 [24000/38018 (63%)]\tLoss: 0.368233\n",
      "Train Epoch: 20 [25600/38018 (67%)]\tLoss: 0.000044\n",
      "Train Epoch: 20 [27200/38018 (72%)]\tLoss: 0.000010\n",
      "Train Epoch: 20 [28800/38018 (76%)]\tLoss: 0.006688\n",
      "Train Epoch: 20 [30400/38018 (80%)]\tLoss: 0.000038\n",
      "Train Epoch: 20 [32000/38018 (84%)]\tLoss: 0.004789\n",
      "Train Epoch: 20 [33600/38018 (88%)]\tLoss: 0.049208\n",
      "Train Epoch: 20 [35200/38018 (93%)]\tLoss: 0.007056\n",
      "Train Epoch: 20 [36800/38018 (97%)]\tLoss: 0.076588\n",
      "Train Loss: 0.0255 Acc: 0.9920\n",
      "Val Loss: 0.0364 Acc: 0.9888\n",
      "Epoch 21/39\n",
      "----------\n",
      "Train Epoch: 21 [0/38018 (0%)]\tLoss: 0.004518\n",
      "Train Epoch: 21 [1600/38018 (4%)]\tLoss: 0.000750\n",
      "Train Epoch: 21 [3200/38018 (8%)]\tLoss: 0.000899\n",
      "Train Epoch: 21 [4800/38018 (13%)]\tLoss: 0.000317\n",
      "Train Epoch: 21 [6400/38018 (17%)]\tLoss: 0.000002\n",
      "Train Epoch: 21 [8000/38018 (21%)]\tLoss: 0.004165\n",
      "Train Epoch: 21 [9600/38018 (25%)]\tLoss: 0.004736\n",
      "Train Epoch: 21 [11200/38018 (29%)]\tLoss: 0.000010\n",
      "Train Epoch: 21 [12800/38018 (34%)]\tLoss: 0.000636\n",
      "Train Epoch: 21 [14400/38018 (38%)]\tLoss: 0.000109\n",
      "Train Epoch: 21 [16000/38018 (42%)]\tLoss: 0.004946\n",
      "Train Epoch: 21 [17600/38018 (46%)]\tLoss: 0.317698\n",
      "Train Epoch: 21 [19200/38018 (50%)]\tLoss: 0.000080\n",
      "Train Epoch: 21 [20800/38018 (55%)]\tLoss: 0.069742\n",
      "Train Epoch: 21 [22400/38018 (59%)]\tLoss: 0.000279\n",
      "Train Epoch: 21 [24000/38018 (63%)]\tLoss: 0.006257\n",
      "Train Epoch: 21 [25600/38018 (67%)]\tLoss: 0.008390\n",
      "Train Epoch: 21 [27200/38018 (72%)]\tLoss: 0.029254\n",
      "Train Epoch: 21 [28800/38018 (76%)]\tLoss: 0.001425\n",
      "Train Epoch: 21 [30400/38018 (80%)]\tLoss: 0.166166\n",
      "Train Epoch: 21 [32000/38018 (84%)]\tLoss: 0.000216\n",
      "Train Epoch: 21 [33600/38018 (88%)]\tLoss: 0.041546\n",
      "Train Epoch: 21 [35200/38018 (93%)]\tLoss: 0.017786\n",
      "Train Epoch: 21 [36800/38018 (97%)]\tLoss: 0.000027\n",
      "Train Loss: 0.0198 Acc: 0.9937\n",
      "Val Loss: 0.0654 Acc: 0.9806\n",
      "Epoch 22/39\n",
      "----------\n",
      "Train Epoch: 22 [0/38018 (0%)]\tLoss: 0.004504\n",
      "Train Epoch: 22 [1600/38018 (4%)]\tLoss: 0.002018\n",
      "Train Epoch: 22 [3200/38018 (8%)]\tLoss: 0.001870\n",
      "Train Epoch: 22 [4800/38018 (13%)]\tLoss: 0.000604\n",
      "Train Epoch: 22 [6400/38018 (17%)]\tLoss: 0.005672\n",
      "Train Epoch: 22 [8000/38018 (21%)]\tLoss: 0.003960\n",
      "Train Epoch: 22 [9600/38018 (25%)]\tLoss: 0.035324\n",
      "Train Epoch: 22 [11200/38018 (29%)]\tLoss: 0.005492\n",
      "Train Epoch: 22 [12800/38018 (34%)]\tLoss: 0.000530\n",
      "Train Epoch: 22 [14400/38018 (38%)]\tLoss: 0.297520\n",
      "Train Epoch: 22 [16000/38018 (42%)]\tLoss: 0.000341\n",
      "Train Epoch: 22 [17600/38018 (46%)]\tLoss: 0.000051\n",
      "Train Epoch: 22 [19200/38018 (50%)]\tLoss: 0.000267\n",
      "Train Epoch: 22 [20800/38018 (55%)]\tLoss: 0.002509\n",
      "Train Epoch: 22 [22400/38018 (59%)]\tLoss: 0.000013\n",
      "Train Epoch: 22 [24000/38018 (63%)]\tLoss: 0.003341\n",
      "Train Epoch: 22 [25600/38018 (67%)]\tLoss: 0.000311\n",
      "Train Epoch: 22 [27200/38018 (72%)]\tLoss: 0.001991\n",
      "Train Epoch: 22 [28800/38018 (76%)]\tLoss: 0.003164\n",
      "Train Epoch: 22 [30400/38018 (80%)]\tLoss: 0.030372\n",
      "Train Epoch: 22 [32000/38018 (84%)]\tLoss: 0.012108\n",
      "Train Epoch: 22 [33600/38018 (88%)]\tLoss: 0.012374\n",
      "Train Epoch: 22 [35200/38018 (93%)]\tLoss: 0.003696\n",
      "Train Epoch: 22 [36800/38018 (97%)]\tLoss: 0.000289\n",
      "Train Loss: 0.0323 Acc: 0.9900\n",
      "Val Loss: 0.0300 Acc: 0.9924\n",
      "Epoch 23/39\n",
      "----------\n",
      "Train Epoch: 23 [0/38018 (0%)]\tLoss: 0.252027\n",
      "Train Epoch: 23 [1600/38018 (4%)]\tLoss: 0.000150\n",
      "Train Epoch: 23 [3200/38018 (8%)]\tLoss: 0.000063\n",
      "Train Epoch: 23 [4800/38018 (13%)]\tLoss: 0.000169\n",
      "Train Epoch: 23 [6400/38018 (17%)]\tLoss: 0.000001\n",
      "Train Epoch: 23 [8000/38018 (21%)]\tLoss: 0.000004\n",
      "Train Epoch: 23 [9600/38018 (25%)]\tLoss: 0.007261\n",
      "Train Epoch: 23 [11200/38018 (29%)]\tLoss: 0.021661\n",
      "Train Epoch: 23 [12800/38018 (34%)]\tLoss: 0.168605\n",
      "Train Epoch: 23 [14400/38018 (38%)]\tLoss: 0.000505\n",
      "Train Epoch: 23 [16000/38018 (42%)]\tLoss: 0.000937\n",
      "Train Epoch: 23 [17600/38018 (46%)]\tLoss: 0.000025\n",
      "Train Epoch: 23 [19200/38018 (50%)]\tLoss: 0.069258\n",
      "Train Epoch: 23 [20800/38018 (55%)]\tLoss: 0.087460\n",
      "Train Epoch: 23 [22400/38018 (59%)]\tLoss: 0.000508\n",
      "Train Epoch: 23 [24000/38018 (63%)]\tLoss: 0.000014\n",
      "Train Epoch: 23 [25600/38018 (67%)]\tLoss: 0.000007\n",
      "Train Epoch: 23 [27200/38018 (72%)]\tLoss: 0.001323\n",
      "Train Epoch: 23 [28800/38018 (76%)]\tLoss: 0.192234\n",
      "Train Epoch: 23 [30400/38018 (80%)]\tLoss: 0.002211\n",
      "Train Epoch: 23 [32000/38018 (84%)]\tLoss: 0.000037\n",
      "Train Epoch: 23 [33600/38018 (88%)]\tLoss: 0.000774\n",
      "Train Epoch: 23 [35200/38018 (93%)]\tLoss: 0.078195\n",
      "Train Epoch: 23 [36800/38018 (97%)]\tLoss: 0.000901\n",
      "Train Loss: 0.0204 Acc: 0.9938\n",
      "Val Loss: 0.0121 Acc: 0.9964\n",
      "Epoch 24/39\n",
      "----------\n",
      "Train Epoch: 24 [0/38018 (0%)]\tLoss: 0.000038\n",
      "Train Epoch: 24 [1600/38018 (4%)]\tLoss: 0.059045\n",
      "Train Epoch: 24 [3200/38018 (8%)]\tLoss: 0.007319\n",
      "Train Epoch: 24 [4800/38018 (13%)]\tLoss: 0.000114\n",
      "Train Epoch: 24 [6400/38018 (17%)]\tLoss: 0.006883\n",
      "Train Epoch: 24 [8000/38018 (21%)]\tLoss: 0.000231\n",
      "Train Epoch: 24 [9600/38018 (25%)]\tLoss: 0.010648\n",
      "Train Epoch: 24 [11200/38018 (29%)]\tLoss: 0.185108\n",
      "Train Epoch: 24 [12800/38018 (34%)]\tLoss: 0.000039\n",
      "Train Epoch: 24 [14400/38018 (38%)]\tLoss: 0.000020\n",
      "Train Epoch: 24 [16000/38018 (42%)]\tLoss: 0.023636\n",
      "Train Epoch: 24 [17600/38018 (46%)]\tLoss: 0.228393\n",
      "Train Epoch: 24 [19200/38018 (50%)]\tLoss: 0.001267\n",
      "Train Epoch: 24 [20800/38018 (55%)]\tLoss: 0.000027\n",
      "Train Epoch: 24 [22400/38018 (59%)]\tLoss: 0.000166\n",
      "Train Epoch: 24 [24000/38018 (63%)]\tLoss: 0.013593\n",
      "Train Epoch: 24 [25600/38018 (67%)]\tLoss: 0.001871\n",
      "Train Epoch: 24 [27200/38018 (72%)]\tLoss: 0.000447\n",
      "Train Epoch: 24 [28800/38018 (76%)]\tLoss: 0.000731\n",
      "Train Epoch: 24 [30400/38018 (80%)]\tLoss: 0.006574\n",
      "Train Epoch: 24 [32000/38018 (84%)]\tLoss: 0.000094\n",
      "Train Epoch: 24 [33600/38018 (88%)]\tLoss: 0.000391\n",
      "Train Epoch: 24 [35200/38018 (93%)]\tLoss: 0.000053\n",
      "Train Epoch: 24 [36800/38018 (97%)]\tLoss: 0.000011\n",
      "Train Loss: 0.0228 Acc: 0.9922\n",
      "Val Loss: 0.0092 Acc: 0.9968\n",
      "Epoch 25/39\n",
      "----------\n",
      "Train Epoch: 25 [0/38018 (0%)]\tLoss: 0.000004\n",
      "Train Epoch: 25 [1600/38018 (4%)]\tLoss: 0.022157\n",
      "Train Epoch: 25 [3200/38018 (8%)]\tLoss: 0.000177\n",
      "Train Epoch: 25 [4800/38018 (13%)]\tLoss: 0.000008\n",
      "Train Epoch: 25 [6400/38018 (17%)]\tLoss: 0.001411\n",
      "Train Epoch: 25 [8000/38018 (21%)]\tLoss: 0.006717\n",
      "Train Epoch: 25 [9600/38018 (25%)]\tLoss: 0.044644\n",
      "Train Epoch: 25 [11200/38018 (29%)]\tLoss: 0.000115\n",
      "Train Epoch: 25 [12800/38018 (34%)]\tLoss: 0.000005\n",
      "Train Epoch: 25 [14400/38018 (38%)]\tLoss: 0.008144\n",
      "Train Epoch: 25 [16000/38018 (42%)]\tLoss: 0.000279\n",
      "Train Epoch: 25 [17600/38018 (46%)]\tLoss: 0.000049\n",
      "Train Epoch: 25 [19200/38018 (50%)]\tLoss: 0.011245\n",
      "Train Epoch: 25 [20800/38018 (55%)]\tLoss: 0.004475\n",
      "Train Epoch: 25 [22400/38018 (59%)]\tLoss: 0.002227\n",
      "Train Epoch: 25 [24000/38018 (63%)]\tLoss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25 [25600/38018 (67%)]\tLoss: 0.000025\n",
      "Train Epoch: 25 [27200/38018 (72%)]\tLoss: 0.000133\n",
      "Train Epoch: 25 [28800/38018 (76%)]\tLoss: 0.001276\n",
      "Train Epoch: 25 [30400/38018 (80%)]\tLoss: 0.177783\n",
      "Train Epoch: 25 [32000/38018 (84%)]\tLoss: 0.000154\n",
      "Train Epoch: 25 [33600/38018 (88%)]\tLoss: 0.003019\n",
      "Train Epoch: 25 [35200/38018 (93%)]\tLoss: 0.000448\n",
      "Train Epoch: 25 [36800/38018 (97%)]\tLoss: 0.010395\n",
      "Train Loss: 0.0185 Acc: 0.9943\n",
      "Val Loss: 0.0107 Acc: 0.9966\n",
      "Epoch 26/39\n",
      "----------\n",
      "Train Epoch: 26 [0/38018 (0%)]\tLoss: 0.000013\n",
      "Train Epoch: 26 [1600/38018 (4%)]\tLoss: 0.000304\n",
      "Train Epoch: 26 [3200/38018 (8%)]\tLoss: 0.010234\n",
      "Train Epoch: 26 [4800/38018 (13%)]\tLoss: 0.000613\n",
      "Train Epoch: 26 [6400/38018 (17%)]\tLoss: 0.000000\n",
      "Train Epoch: 26 [8000/38018 (21%)]\tLoss: 0.003159\n",
      "Train Epoch: 26 [9600/38018 (25%)]\tLoss: 0.007474\n",
      "Train Epoch: 26 [11200/38018 (29%)]\tLoss: 0.000006\n",
      "Train Epoch: 26 [12800/38018 (34%)]\tLoss: 0.000008\n",
      "Train Epoch: 26 [14400/38018 (38%)]\tLoss: 0.000986\n",
      "Train Epoch: 26 [16000/38018 (42%)]\tLoss: 0.005193\n",
      "Train Epoch: 26 [17600/38018 (46%)]\tLoss: 0.001220\n",
      "Train Epoch: 26 [19200/38018 (50%)]\tLoss: 0.018626\n",
      "Train Epoch: 26 [20800/38018 (55%)]\tLoss: 0.000762\n",
      "Train Epoch: 26 [22400/38018 (59%)]\tLoss: 0.000064\n",
      "Train Epoch: 26 [24000/38018 (63%)]\tLoss: 0.003991\n",
      "Train Epoch: 26 [25600/38018 (67%)]\tLoss: 0.000013\n",
      "Train Epoch: 26 [27200/38018 (72%)]\tLoss: 0.000002\n",
      "Train Epoch: 26 [28800/38018 (76%)]\tLoss: 0.000003\n",
      "Train Epoch: 26 [30400/38018 (80%)]\tLoss: 0.000064\n",
      "Train Epoch: 26 [32000/38018 (84%)]\tLoss: 0.000422\n",
      "Train Epoch: 26 [33600/38018 (88%)]\tLoss: 0.003209\n",
      "Train Epoch: 26 [35200/38018 (93%)]\tLoss: 0.000872\n",
      "Train Epoch: 26 [36800/38018 (97%)]\tLoss: 0.000000\n",
      "Train Loss: 0.0255 Acc: 0.9934\n",
      "Val Loss: 0.0248 Acc: 0.9935\n",
      "Epoch 27/39\n",
      "----------\n",
      "Train Epoch: 27 [0/38018 (0%)]\tLoss: 0.043633\n",
      "Train Epoch: 27 [1600/38018 (4%)]\tLoss: 0.093056\n",
      "Train Epoch: 27 [3200/38018 (8%)]\tLoss: 0.000015\n",
      "Train Epoch: 27 [4800/38018 (13%)]\tLoss: 0.000003\n",
      "Train Epoch: 27 [6400/38018 (17%)]\tLoss: 0.040918\n",
      "Train Epoch: 27 [8000/38018 (21%)]\tLoss: 0.000144\n",
      "Train Epoch: 27 [9600/38018 (25%)]\tLoss: 0.000002\n",
      "Train Epoch: 27 [11200/38018 (29%)]\tLoss: 0.006783\n",
      "Train Epoch: 27 [12800/38018 (34%)]\tLoss: 0.145836\n",
      "Train Epoch: 27 [14400/38018 (38%)]\tLoss: 0.002968\n",
      "Train Epoch: 27 [16000/38018 (42%)]\tLoss: 0.006704\n",
      "Train Epoch: 27 [17600/38018 (46%)]\tLoss: 0.053729\n",
      "Train Epoch: 27 [19200/38018 (50%)]\tLoss: 0.001238\n",
      "Train Epoch: 27 [20800/38018 (55%)]\tLoss: 0.000195\n",
      "Train Epoch: 27 [22400/38018 (59%)]\tLoss: 0.000029\n",
      "Train Epoch: 27 [24000/38018 (63%)]\tLoss: 0.212229\n",
      "Train Epoch: 27 [25600/38018 (67%)]\tLoss: 0.073244\n",
      "Train Epoch: 27 [27200/38018 (72%)]\tLoss: 0.000024\n",
      "Train Epoch: 27 [28800/38018 (76%)]\tLoss: 0.000031\n",
      "Train Epoch: 27 [30400/38018 (80%)]\tLoss: 0.000003\n",
      "Train Epoch: 27 [32000/38018 (84%)]\tLoss: 0.000652\n",
      "Train Epoch: 27 [33600/38018 (88%)]\tLoss: 0.000983\n",
      "Train Epoch: 27 [35200/38018 (93%)]\tLoss: 0.000494\n",
      "Train Epoch: 27 [36800/38018 (97%)]\tLoss: 0.002499\n",
      "Train Loss: 0.0161 Acc: 0.9948\n",
      "Val Loss: 0.0356 Acc: 0.9907\n",
      "Epoch 28/39\n",
      "----------\n",
      "Train Epoch: 28 [0/38018 (0%)]\tLoss: 0.000296\n",
      "Train Epoch: 28 [1600/38018 (4%)]\tLoss: 0.006553\n",
      "Train Epoch: 28 [3200/38018 (8%)]\tLoss: 0.002289\n",
      "Train Epoch: 28 [4800/38018 (13%)]\tLoss: 0.000690\n",
      "Train Epoch: 28 [6400/38018 (17%)]\tLoss: 0.000116\n",
      "Train Epoch: 28 [8000/38018 (21%)]\tLoss: 0.000425\n",
      "Train Epoch: 28 [9600/38018 (25%)]\tLoss: 0.109991\n",
      "Train Epoch: 28 [11200/38018 (29%)]\tLoss: 0.000089\n",
      "Train Epoch: 28 [12800/38018 (34%)]\tLoss: 0.002493\n",
      "Train Epoch: 28 [14400/38018 (38%)]\tLoss: 0.000041\n",
      "Train Epoch: 28 [16000/38018 (42%)]\tLoss: 0.000122\n",
      "Train Epoch: 28 [17600/38018 (46%)]\tLoss: 0.001279\n",
      "Train Epoch: 28 [19200/38018 (50%)]\tLoss: 0.042858\n",
      "Train Epoch: 28 [20800/38018 (55%)]\tLoss: 0.002561\n",
      "Train Epoch: 28 [22400/38018 (59%)]\tLoss: 0.000177\n",
      "Train Epoch: 28 [24000/38018 (63%)]\tLoss: 0.000153\n",
      "Train Epoch: 28 [25600/38018 (67%)]\tLoss: 0.001676\n",
      "Train Epoch: 28 [27200/38018 (72%)]\tLoss: 0.000284\n",
      "Train Epoch: 28 [28800/38018 (76%)]\tLoss: 0.005706\n",
      "Train Epoch: 28 [30400/38018 (80%)]\tLoss: 0.003674\n",
      "Train Epoch: 28 [32000/38018 (84%)]\tLoss: 0.003047\n",
      "Train Epoch: 28 [33600/38018 (88%)]\tLoss: 0.022049\n",
      "Train Epoch: 28 [35200/38018 (93%)]\tLoss: 0.003379\n",
      "Train Epoch: 28 [36800/38018 (97%)]\tLoss: 0.000228\n",
      "Train Loss: 0.0188 Acc: 0.9945\n",
      "Val Loss: 0.0084 Acc: 0.9975\n",
      "Epoch 29/39\n",
      "----------\n",
      "Train Epoch: 29 [0/38018 (0%)]\tLoss: 0.001256\n",
      "Train Epoch: 29 [1600/38018 (4%)]\tLoss: 0.020211\n",
      "Train Epoch: 29 [3200/38018 (8%)]\tLoss: 0.004721\n",
      "Train Epoch: 29 [4800/38018 (13%)]\tLoss: 0.068425\n",
      "Train Epoch: 29 [6400/38018 (17%)]\tLoss: 0.000198\n",
      "Train Epoch: 29 [8000/38018 (21%)]\tLoss: 0.000854\n",
      "Train Epoch: 29 [9600/38018 (25%)]\tLoss: 0.000976\n",
      "Train Epoch: 29 [11200/38018 (29%)]\tLoss: 0.011321\n",
      "Train Epoch: 29 [12800/38018 (34%)]\tLoss: 0.082178\n",
      "Train Epoch: 29 [14400/38018 (38%)]\tLoss: 0.054428\n",
      "Train Epoch: 29 [16000/38018 (42%)]\tLoss: 0.003087\n",
      "Train Epoch: 29 [17600/38018 (46%)]\tLoss: 0.000462\n",
      "Train Epoch: 29 [19200/38018 (50%)]\tLoss: 0.000012\n",
      "Train Epoch: 29 [20800/38018 (55%)]\tLoss: 0.000013\n",
      "Train Epoch: 29 [22400/38018 (59%)]\tLoss: 0.006889\n",
      "Train Epoch: 29 [24000/38018 (63%)]\tLoss: 0.000830\n",
      "Train Epoch: 29 [25600/38018 (67%)]\tLoss: 0.013027\n",
      "Train Epoch: 29 [27200/38018 (72%)]\tLoss: 0.034316\n",
      "Train Epoch: 29 [28800/38018 (76%)]\tLoss: 0.001704\n",
      "Train Epoch: 29 [30400/38018 (80%)]\tLoss: 0.000765\n",
      "Train Epoch: 29 [32000/38018 (84%)]\tLoss: 0.000717\n",
      "Train Epoch: 29 [33600/38018 (88%)]\tLoss: 0.200104\n",
      "Train Epoch: 29 [35200/38018 (93%)]\tLoss: 0.078561\n",
      "Train Epoch: 29 [36800/38018 (97%)]\tLoss: 0.003292\n",
      "Train Loss: 0.0193 Acc: 0.9943\n",
      "Val Loss: 0.0546 Acc: 0.9846\n",
      "Epoch 30/39\n",
      "----------\n",
      "Train Epoch: 30 [0/38018 (0%)]\tLoss: 0.000033\n",
      "Train Epoch: 30 [1600/38018 (4%)]\tLoss: 0.000097\n",
      "Train Epoch: 30 [3200/38018 (8%)]\tLoss: 0.015320\n",
      "Train Epoch: 30 [4800/38018 (13%)]\tLoss: 0.000195\n",
      "Train Epoch: 30 [6400/38018 (17%)]\tLoss: 0.004910\n",
      "Train Epoch: 30 [8000/38018 (21%)]\tLoss: 0.000179\n",
      "Train Epoch: 30 [9600/38018 (25%)]\tLoss: 0.000119\n",
      "Train Epoch: 30 [11200/38018 (29%)]\tLoss: 0.000100\n",
      "Train Epoch: 30 [12800/38018 (34%)]\tLoss: 0.000853\n",
      "Train Epoch: 30 [14400/38018 (38%)]\tLoss: 0.006510\n",
      "Train Epoch: 30 [16000/38018 (42%)]\tLoss: 0.000000\n",
      "Train Epoch: 30 [17600/38018 (46%)]\tLoss: 0.000020\n",
      "Train Epoch: 30 [19200/38018 (50%)]\tLoss: 0.021088\n",
      "Train Epoch: 30 [20800/38018 (55%)]\tLoss: 0.001976\n",
      "Train Epoch: 30 [22400/38018 (59%)]\tLoss: 0.000236\n",
      "Train Epoch: 30 [24000/38018 (63%)]\tLoss: 1.091063\n",
      "Train Epoch: 30 [25600/38018 (67%)]\tLoss: 0.018193\n",
      "Train Epoch: 30 [27200/38018 (72%)]\tLoss: 0.000321\n",
      "Train Epoch: 30 [28800/38018 (76%)]\tLoss: 0.002222\n",
      "Train Epoch: 30 [30400/38018 (80%)]\tLoss: 0.000606\n",
      "Train Epoch: 30 [32000/38018 (84%)]\tLoss: 0.002265\n",
      "Train Epoch: 30 [33600/38018 (88%)]\tLoss: 0.002423\n",
      "Train Epoch: 30 [35200/38018 (93%)]\tLoss: 0.001356\n",
      "Train Epoch: 30 [36800/38018 (97%)]\tLoss: 0.000219\n",
      "Train Loss: 0.0181 Acc: 0.9950\n",
      "Val Loss: 0.0117 Acc: 0.9958\n",
      "Epoch 31/39\n",
      "----------\n",
      "Train Epoch: 31 [0/38018 (0%)]\tLoss: 0.002877\n",
      "Train Epoch: 31 [1600/38018 (4%)]\tLoss: 0.001395\n",
      "Train Epoch: 31 [3200/38018 (8%)]\tLoss: 0.002046\n",
      "Train Epoch: 31 [4800/38018 (13%)]\tLoss: 0.000143\n",
      "Train Epoch: 31 [6400/38018 (17%)]\tLoss: 0.001448\n",
      "Train Epoch: 31 [8000/38018 (21%)]\tLoss: 0.007731\n",
      "Train Epoch: 31 [9600/38018 (25%)]\tLoss: 0.000181\n",
      "Train Epoch: 31 [11200/38018 (29%)]\tLoss: 0.000052\n",
      "Train Epoch: 31 [12800/38018 (34%)]\tLoss: 0.001768\n",
      "Train Epoch: 31 [14400/38018 (38%)]\tLoss: 0.090604\n",
      "Train Epoch: 31 [16000/38018 (42%)]\tLoss: 0.005756\n",
      "Train Epoch: 31 [17600/38018 (46%)]\tLoss: 0.000224\n",
      "Train Epoch: 31 [19200/38018 (50%)]\tLoss: 0.000001\n",
      "Train Epoch: 31 [20800/38018 (55%)]\tLoss: 0.004200\n",
      "Train Epoch: 31 [22400/38018 (59%)]\tLoss: 0.104130\n",
      "Train Epoch: 31 [24000/38018 (63%)]\tLoss: 0.001549\n",
      "Train Epoch: 31 [25600/38018 (67%)]\tLoss: 0.002252\n",
      "Train Epoch: 31 [27200/38018 (72%)]\tLoss: 0.027718\n",
      "Train Epoch: 31 [28800/38018 (76%)]\tLoss: 0.000001\n",
      "Train Epoch: 31 [30400/38018 (80%)]\tLoss: 0.000027\n",
      "Train Epoch: 31 [32000/38018 (84%)]\tLoss: 0.000201\n",
      "Train Epoch: 31 [33600/38018 (88%)]\tLoss: 0.000106\n",
      "Train Epoch: 31 [35200/38018 (93%)]\tLoss: 0.000000\n",
      "Train Epoch: 31 [36800/38018 (97%)]\tLoss: 0.000089\n",
      "Train Loss: 0.0176 Acc: 0.9944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0157 Acc: 0.9956\n",
      "Epoch 32/39\n",
      "----------\n",
      "Train Epoch: 32 [0/38018 (0%)]\tLoss: 0.001549\n",
      "Train Epoch: 32 [1600/38018 (4%)]\tLoss: 0.019152\n",
      "Train Epoch: 32 [3200/38018 (8%)]\tLoss: 0.000000\n",
      "Train Epoch: 32 [4800/38018 (13%)]\tLoss: 0.000000\n",
      "Train Epoch: 32 [6400/38018 (17%)]\tLoss: 0.003364\n",
      "Train Epoch: 32 [8000/38018 (21%)]\tLoss: 0.000037\n",
      "Train Epoch: 32 [9600/38018 (25%)]\tLoss: 0.000377\n",
      "Train Epoch: 32 [11200/38018 (29%)]\tLoss: 0.003982\n",
      "Train Epoch: 32 [12800/38018 (34%)]\tLoss: 0.000157\n",
      "Train Epoch: 32 [14400/38018 (38%)]\tLoss: 0.000014\n",
      "Train Epoch: 32 [16000/38018 (42%)]\tLoss: 0.000004\n",
      "Train Epoch: 32 [17600/38018 (46%)]\tLoss: 0.000007\n",
      "Train Epoch: 32 [19200/38018 (50%)]\tLoss: 0.000078\n",
      "Train Epoch: 32 [20800/38018 (55%)]\tLoss: 0.000033\n",
      "Train Epoch: 32 [22400/38018 (59%)]\tLoss: 0.000009\n",
      "Train Epoch: 32 [24000/38018 (63%)]\tLoss: 0.027943\n",
      "Train Epoch: 32 [25600/38018 (67%)]\tLoss: 0.007808\n",
      "Train Epoch: 32 [27200/38018 (72%)]\tLoss: 0.078935\n",
      "Train Epoch: 32 [28800/38018 (76%)]\tLoss: 0.001865\n",
      "Train Epoch: 32 [30400/38018 (80%)]\tLoss: 0.002398\n",
      "Train Epoch: 32 [32000/38018 (84%)]\tLoss: 0.000522\n",
      "Train Epoch: 32 [33600/38018 (88%)]\tLoss: 0.000000\n",
      "Train Epoch: 32 [35200/38018 (93%)]\tLoss: 0.000022\n",
      "Train Epoch: 32 [36800/38018 (97%)]\tLoss: 0.000007\n",
      "Train Loss: 0.0148 Acc: 0.9959\n",
      "Val Loss: 0.0335 Acc: 0.9920\n",
      "Epoch 33/39\n",
      "----------\n",
      "Train Epoch: 33 [0/38018 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 33 [1600/38018 (4%)]\tLoss: 0.005780\n",
      "Train Epoch: 33 [3200/38018 (8%)]\tLoss: 0.037900\n",
      "Train Epoch: 33 [4800/38018 (13%)]\tLoss: 0.006687\n",
      "Train Epoch: 33 [6400/38018 (17%)]\tLoss: 0.002166\n",
      "Train Epoch: 33 [8000/38018 (21%)]\tLoss: 0.000075\n",
      "Train Epoch: 33 [9600/38018 (25%)]\tLoss: 0.002974\n",
      "Train Epoch: 33 [11200/38018 (29%)]\tLoss: 0.432983\n",
      "Train Epoch: 33 [12800/38018 (34%)]\tLoss: 0.000103\n",
      "Train Epoch: 33 [14400/38018 (38%)]\tLoss: 0.000001\n",
      "Train Epoch: 33 [16000/38018 (42%)]\tLoss: 0.000001\n",
      "Train Epoch: 33 [17600/38018 (46%)]\tLoss: 0.003576\n",
      "Train Epoch: 33 [19200/38018 (50%)]\tLoss: 0.000062\n",
      "Train Epoch: 33 [20800/38018 (55%)]\tLoss: 0.060993\n",
      "Train Epoch: 33 [22400/38018 (59%)]\tLoss: 0.001513\n",
      "Train Epoch: 33 [24000/38018 (63%)]\tLoss: 0.002494\n",
      "Train Epoch: 33 [25600/38018 (67%)]\tLoss: 0.091982\n",
      "Train Epoch: 33 [27200/38018 (72%)]\tLoss: 0.005136\n",
      "Train Epoch: 33 [28800/38018 (76%)]\tLoss: 0.000031\n",
      "Train Epoch: 33 [30400/38018 (80%)]\tLoss: 0.000022\n",
      "Train Epoch: 33 [32000/38018 (84%)]\tLoss: 0.000102\n",
      "Train Epoch: 33 [33600/38018 (88%)]\tLoss: 0.001438\n",
      "Train Epoch: 33 [35200/38018 (93%)]\tLoss: 0.000007\n",
      "Train Epoch: 33 [36800/38018 (97%)]\tLoss: 0.001113\n",
      "Train Loss: 0.0146 Acc: 0.9959\n",
      "Val Loss: 0.0222 Acc: 0.9928\n",
      "Epoch 34/39\n",
      "----------\n",
      "Train Epoch: 34 [0/38018 (0%)]\tLoss: 0.000684\n",
      "Train Epoch: 34 [1600/38018 (4%)]\tLoss: 0.001278\n",
      "Train Epoch: 34 [3200/38018 (8%)]\tLoss: 0.000275\n",
      "Train Epoch: 34 [4800/38018 (13%)]\tLoss: 0.000175\n",
      "Train Epoch: 34 [6400/38018 (17%)]\tLoss: 0.010720\n",
      "Train Epoch: 34 [8000/38018 (21%)]\tLoss: 0.068466\n",
      "Train Epoch: 34 [9600/38018 (25%)]\tLoss: 0.000265\n",
      "Train Epoch: 34 [11200/38018 (29%)]\tLoss: 0.000233\n",
      "Train Epoch: 34 [12800/38018 (34%)]\tLoss: 0.000061\n",
      "Train Epoch: 34 [14400/38018 (38%)]\tLoss: 0.001507\n",
      "Train Epoch: 34 [16000/38018 (42%)]\tLoss: 0.005079\n",
      "Train Epoch: 34 [17600/38018 (46%)]\tLoss: 0.042442\n",
      "Train Epoch: 34 [19200/38018 (50%)]\tLoss: 0.000425\n",
      "Train Epoch: 34 [20800/38018 (55%)]\tLoss: 0.000001\n",
      "Train Epoch: 34 [22400/38018 (59%)]\tLoss: 0.000035\n",
      "Train Epoch: 34 [24000/38018 (63%)]\tLoss: 0.473712\n",
      "Train Epoch: 34 [25600/38018 (67%)]\tLoss: 0.000023\n",
      "Train Epoch: 34 [27200/38018 (72%)]\tLoss: 0.001271\n",
      "Train Epoch: 34 [28800/38018 (76%)]\tLoss: 0.000364\n",
      "Train Epoch: 34 [30400/38018 (80%)]\tLoss: 0.000775\n",
      "Train Epoch: 34 [32000/38018 (84%)]\tLoss: 0.000617\n",
      "Train Epoch: 34 [33600/38018 (88%)]\tLoss: 0.000361\n",
      "Train Epoch: 34 [35200/38018 (93%)]\tLoss: 0.002666\n",
      "Train Epoch: 34 [36800/38018 (97%)]\tLoss: 0.000960\n",
      "Train Loss: 0.0177 Acc: 0.9947\n",
      "Val Loss: 0.0062 Acc: 0.9977\n",
      "Epoch 35/39\n",
      "----------\n",
      "Train Epoch: 35 [0/38018 (0%)]\tLoss: 0.000373\n",
      "Train Epoch: 35 [1600/38018 (4%)]\tLoss: 0.000026\n",
      "Train Epoch: 35 [3200/38018 (8%)]\tLoss: 0.006372\n",
      "Train Epoch: 35 [4800/38018 (13%)]\tLoss: 0.000439\n",
      "Train Epoch: 35 [6400/38018 (17%)]\tLoss: 0.000059\n",
      "Train Epoch: 35 [8000/38018 (21%)]\tLoss: 0.001216\n",
      "Train Epoch: 35 [9600/38018 (25%)]\tLoss: 0.001483\n",
      "Train Epoch: 35 [11200/38018 (29%)]\tLoss: 0.000205\n",
      "Train Epoch: 35 [12800/38018 (34%)]\tLoss: 0.000001\n",
      "Train Epoch: 35 [14400/38018 (38%)]\tLoss: 0.000081\n",
      "Train Epoch: 35 [16000/38018 (42%)]\tLoss: 0.000015\n",
      "Train Epoch: 35 [17600/38018 (46%)]\tLoss: 0.000001\n",
      "Train Epoch: 35 [19200/38018 (50%)]\tLoss: 0.000173\n",
      "Train Epoch: 35 [20800/38018 (55%)]\tLoss: 0.000096\n",
      "Train Epoch: 35 [22400/38018 (59%)]\tLoss: 0.000006\n",
      "Train Epoch: 35 [24000/38018 (63%)]\tLoss: 0.022527\n",
      "Train Epoch: 35 [25600/38018 (67%)]\tLoss: 0.498508\n",
      "Train Epoch: 35 [27200/38018 (72%)]\tLoss: 0.003428\n",
      "Train Epoch: 35 [28800/38018 (76%)]\tLoss: 0.003607\n",
      "Train Epoch: 35 [30400/38018 (80%)]\tLoss: 0.072489\n",
      "Train Epoch: 35 [32000/38018 (84%)]\tLoss: 0.000261\n",
      "Train Epoch: 35 [33600/38018 (88%)]\tLoss: 0.001035\n",
      "Train Epoch: 35 [35200/38018 (93%)]\tLoss: 0.000264\n",
      "Train Epoch: 35 [36800/38018 (97%)]\tLoss: 0.000004\n",
      "Train Loss: 0.0140 Acc: 0.9963\n",
      "Val Loss: 0.0107 Acc: 0.9979\n",
      "Epoch 36/39\n",
      "----------\n",
      "Train Epoch: 36 [0/38018 (0%)]\tLoss: 0.000015\n",
      "Train Epoch: 36 [1600/38018 (4%)]\tLoss: 0.000184\n",
      "Train Epoch: 36 [3200/38018 (8%)]\tLoss: 0.000001\n",
      "Train Epoch: 36 [4800/38018 (13%)]\tLoss: 0.002251\n",
      "Train Epoch: 36 [6400/38018 (17%)]\tLoss: 0.001339\n",
      "Train Epoch: 36 [8000/38018 (21%)]\tLoss: 0.171106\n",
      "Train Epoch: 36 [9600/38018 (25%)]\tLoss: 0.003470\n",
      "Train Epoch: 36 [11200/38018 (29%)]\tLoss: 0.016008\n",
      "Train Epoch: 36 [12800/38018 (34%)]\tLoss: 0.000654\n",
      "Train Epoch: 36 [14400/38018 (38%)]\tLoss: 0.000119\n",
      "Train Epoch: 36 [16000/38018 (42%)]\tLoss: 0.000027\n",
      "Train Epoch: 36 [17600/38018 (46%)]\tLoss: 0.000000\n",
      "Train Epoch: 36 [19200/38018 (50%)]\tLoss: 0.000015\n",
      "Train Epoch: 36 [20800/38018 (55%)]\tLoss: 0.001982\n",
      "Train Epoch: 36 [22400/38018 (59%)]\tLoss: 0.001167\n",
      "Train Epoch: 36 [24000/38018 (63%)]\tLoss: 0.000131\n",
      "Train Epoch: 36 [25600/38018 (67%)]\tLoss: 0.000076\n",
      "Train Epoch: 36 [27200/38018 (72%)]\tLoss: 0.000024\n",
      "Train Epoch: 36 [28800/38018 (76%)]\tLoss: 0.000001\n",
      "Train Epoch: 36 [30400/38018 (80%)]\tLoss: 0.000206\n",
      "Train Epoch: 36 [32000/38018 (84%)]\tLoss: 0.000004\n",
      "Train Epoch: 36 [33600/38018 (88%)]\tLoss: 0.000695\n",
      "Train Epoch: 36 [35200/38018 (93%)]\tLoss: 0.007036\n",
      "Train Epoch: 36 [36800/38018 (97%)]\tLoss: 0.000200\n",
      "Train Loss: 0.0126 Acc: 0.9961\n",
      "Val Loss: 0.0075 Acc: 0.9979\n",
      "Epoch 37/39\n",
      "----------\n",
      "Train Epoch: 37 [0/38018 (0%)]\tLoss: 0.000259\n",
      "Train Epoch: 37 [1600/38018 (4%)]\tLoss: 0.000068\n",
      "Train Epoch: 37 [3200/38018 (8%)]\tLoss: 0.000006\n",
      "Train Epoch: 37 [4800/38018 (13%)]\tLoss: 0.068450\n",
      "Train Epoch: 37 [6400/38018 (17%)]\tLoss: 0.041322\n",
      "Train Epoch: 37 [8000/38018 (21%)]\tLoss: 0.086889\n",
      "Train Epoch: 37 [9600/38018 (25%)]\tLoss: 0.000142\n",
      "Train Epoch: 37 [11200/38018 (29%)]\tLoss: 0.095689\n",
      "Train Epoch: 37 [12800/38018 (34%)]\tLoss: 0.000012\n",
      "Train Epoch: 37 [14400/38018 (38%)]\tLoss: 0.011192\n",
      "Train Epoch: 37 [16000/38018 (42%)]\tLoss: 0.000030\n",
      "Train Epoch: 37 [17600/38018 (46%)]\tLoss: 0.001680\n",
      "Train Epoch: 37 [19200/38018 (50%)]\tLoss: 0.000005\n",
      "Train Epoch: 37 [20800/38018 (55%)]\tLoss: 0.000000\n",
      "Train Epoch: 37 [22400/38018 (59%)]\tLoss: 0.000039\n",
      "Train Epoch: 37 [24000/38018 (63%)]\tLoss: 0.000135\n",
      "Train Epoch: 37 [25600/38018 (67%)]\tLoss: 0.000007\n",
      "Train Epoch: 37 [27200/38018 (72%)]\tLoss: 0.076670\n",
      "Train Epoch: 37 [28800/38018 (76%)]\tLoss: 0.000000\n",
      "Train Epoch: 37 [30400/38018 (80%)]\tLoss: 0.000001\n",
      "Train Epoch: 37 [32000/38018 (84%)]\tLoss: 0.000076\n",
      "Train Epoch: 37 [33600/38018 (88%)]\tLoss: 0.002516\n",
      "Train Epoch: 37 [35200/38018 (93%)]\tLoss: 0.000035\n",
      "Train Epoch: 37 [36800/38018 (97%)]\tLoss: 0.000116\n",
      "Train Loss: 0.0141 Acc: 0.9959\n",
      "Val Loss: 0.0325 Acc: 0.9931\n",
      "Epoch 38/39\n",
      "----------\n",
      "Train Epoch: 38 [0/38018 (0%)]\tLoss: 0.002683\n",
      "Train Epoch: 38 [1600/38018 (4%)]\tLoss: 0.000186\n",
      "Train Epoch: 38 [3200/38018 (8%)]\tLoss: 0.000640\n",
      "Train Epoch: 38 [4800/38018 (13%)]\tLoss: 0.009684\n",
      "Train Epoch: 38 [6400/38018 (17%)]\tLoss: 0.000037\n",
      "Train Epoch: 38 [8000/38018 (21%)]\tLoss: 0.000003\n",
      "Train Epoch: 38 [9600/38018 (25%)]\tLoss: 0.005468\n",
      "Train Epoch: 38 [11200/38018 (29%)]\tLoss: 0.000110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 38 [12800/38018 (34%)]\tLoss: 0.006978\n",
      "Train Epoch: 38 [14400/38018 (38%)]\tLoss: 0.000253\n",
      "Train Epoch: 38 [16000/38018 (42%)]\tLoss: 0.000759\n",
      "Train Epoch: 38 [17600/38018 (46%)]\tLoss: 0.001388\n",
      "Train Epoch: 38 [19200/38018 (50%)]\tLoss: 0.000151\n",
      "Train Epoch: 38 [20800/38018 (55%)]\tLoss: 0.001293\n",
      "Train Epoch: 38 [22400/38018 (59%)]\tLoss: 0.000321\n",
      "Train Epoch: 38 [24000/38018 (63%)]\tLoss: 0.000026\n",
      "Train Epoch: 38 [25600/38018 (67%)]\tLoss: 0.000047\n",
      "Train Epoch: 38 [27200/38018 (72%)]\tLoss: 0.000104\n",
      "Train Epoch: 38 [28800/38018 (76%)]\tLoss: 0.000011\n",
      "Train Epoch: 38 [30400/38018 (80%)]\tLoss: 0.008741\n",
      "Train Epoch: 38 [32000/38018 (84%)]\tLoss: 0.000000\n",
      "Train Epoch: 38 [33600/38018 (88%)]\tLoss: 0.002721\n",
      "Train Epoch: 38 [35200/38018 (93%)]\tLoss: 0.000020\n",
      "Train Epoch: 38 [36800/38018 (97%)]\tLoss: 0.000001\n",
      "Train Loss: 0.0158 Acc: 0.9954\n",
      "Val Loss: 0.0298 Acc: 0.9931\n",
      "Epoch 39/39\n",
      "----------\n",
      "Train Epoch: 39 [0/38018 (0%)]\tLoss: 0.000006\n",
      "Train Epoch: 39 [1600/38018 (4%)]\tLoss: 0.000017\n",
      "Train Epoch: 39 [3200/38018 (8%)]\tLoss: 0.000177\n",
      "Train Epoch: 39 [4800/38018 (13%)]\tLoss: 0.000850\n",
      "Train Epoch: 39 [6400/38018 (17%)]\tLoss: 0.000027\n",
      "Train Epoch: 39 [8000/38018 (21%)]\tLoss: 0.000011\n",
      "Train Epoch: 39 [9600/38018 (25%)]\tLoss: 0.000014\n",
      "Train Epoch: 39 [11200/38018 (29%)]\tLoss: 0.000003\n",
      "Train Epoch: 39 [12800/38018 (34%)]\tLoss: 0.000414\n",
      "Train Epoch: 39 [14400/38018 (38%)]\tLoss: 0.000116\n",
      "Train Epoch: 39 [16000/38018 (42%)]\tLoss: 0.026020\n",
      "Train Epoch: 39 [17600/38018 (46%)]\tLoss: 0.000056\n",
      "Train Epoch: 39 [19200/38018 (50%)]\tLoss: 0.000214\n",
      "Train Epoch: 39 [20800/38018 (55%)]\tLoss: 0.000002\n",
      "Train Epoch: 39 [22400/38018 (59%)]\tLoss: 0.000825\n",
      "Train Epoch: 39 [24000/38018 (63%)]\tLoss: 0.423883\n",
      "Train Epoch: 39 [25600/38018 (67%)]\tLoss: 0.000008\n",
      "Train Epoch: 39 [27200/38018 (72%)]\tLoss: 0.037177\n",
      "Train Epoch: 39 [28800/38018 (76%)]\tLoss: 0.000731\n",
      "Train Epoch: 39 [30400/38018 (80%)]\tLoss: 0.029134\n",
      "Train Epoch: 39 [32000/38018 (84%)]\tLoss: 0.000839\n",
      "Train Epoch: 39 [33600/38018 (88%)]\tLoss: 0.002176\n",
      "Train Epoch: 39 [35200/38018 (93%)]\tLoss: 0.000164\n",
      "Train Epoch: 39 [36800/38018 (97%)]\tLoss: 0.000407\n",
      "Train Loss: 0.0156 Acc: 0.9956\n",
      "Val Loss: 0.0196 Acc: 0.9952\n"
     ]
    }
   ],
   "source": [
    "# Define the initial minimum validation loss\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "# Call the training function with the appropriate data loaders\n",
    "train_losses, train_accs, val_losses, val_accs, min_loss = trainVal(\n",
    "    model, criterion, optimizer, num_epochs, min_val_loss, train_loader, val_loader, device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "hwkImo6ft4xa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert the tensors to NumPy arrays\n",
    "\n",
    "train_losses = torch.tensor(train_losses)\n",
    "val_losses = torch.tensor(val_losses)\n",
    "train_accs = torch.tensor(train_accs)\n",
    "val_accs = torch.tensor(val_accs)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accs, label='Training Accuracy')\n",
    "plt.plot(val_accs, label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.26%\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "model.eval()\n",
    "total_test_loss = 0.0\n",
    "correct_test = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        test_loss = criterion(outputs, labels)\n",
    "        total_test_loss += test_loss.item() * images.size(0)\n",
    "        pred = outputs.argmax(dim=1, keepdim=True)\n",
    "        correct_test += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        # Gather predictions and true labels for confusion matrix\n",
    "        all_preds.extend(pred.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "average_test_loss = total_test_loss / len(test_loader.dataset)\n",
    "test_losses.append(average_test_loss)\n",
    "test_accuracies.append(100. * correct_test / len(test_loader.dataset))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_accuracies[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 422    0    0    0]\n",
      " [   0 2320    4   29]\n",
      " [   0    1  986    0]\n",
      " [   0    1    0  989]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       422\n",
      "           1       1.00      0.99      0.99      2353\n",
      "           2       1.00      1.00      1.00       987\n",
      "           3       0.97      1.00      0.99       990\n",
      "\n",
      "    accuracy                           0.99      4752\n",
      "   macro avg       0.99      1.00      0.99      4752\n",
      "weighted avg       0.99      0.99      0.99      4752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "# Classification Report\n",
    "class_report = classification_report(all_labels, all_preds)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "LVk3yha174JE"
   },
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "\n",
    "    Sum = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        #output = model(inputs).to(device).float()\n",
    "        output = model(images)\n",
    "\n",
    "        _,prediction = torch.max(output,1)\n",
    "\n",
    "        pred_label = labels[prediction]\n",
    "        pred_label = pred_label.detach().cpu().numpy()\n",
    "        main_label = labels.detach().cpu().numpy()\n",
    "        bool_list  = list(map(lambda x, y: x == y, pred_label, main_label))\n",
    "        Sum += sum(np.array(bool_list)*1)\n",
    "\n",
    "    #print('Prediction: ', (Sum/len(test_loader.dataset)*100,'%'))\n",
    "    print('Prediction: {:.2f}%'.format(Sum / len(test_loader.dataset) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "js9pMlrn9YRG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 33.16%\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsJtolvNvLrg"
   },
   "source": [
    "----------------------DONE-------------------------"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "graspenv",
   "language": "python",
   "name": "graspenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
