{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, inplanes, outplanes, stride=1, res_conv=False, act_layer=nn.ReLU, groups=1,\n",
    "                 norm_layer=partial(nn.BatchNorm2d, eps=1e-6), drop_block=None, drop_path=None):\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        expansion = 4\n",
    "        med_planes = outplanes // expansion\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, med_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = norm_layer(med_planes)\n",
    "        self.act1 = act_layer(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(med_planes, med_planes, kernel_size=3, stride=stride, groups=groups, padding=1, bias=False)\n",
    "        self.bn2 = norm_layer(med_planes)\n",
    "        self.act2 = act_layer(inplace=True)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(med_planes, outplanes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn3 = norm_layer(outplanes)\n",
    "        self.act3 = act_layer(inplace=True)\n",
    "\n",
    "        if res_conv:\n",
    "            self.residual_conv = nn.Conv2d(inplanes, outplanes, kernel_size=1, stride=stride, padding=0, bias=False)\n",
    "            self.residual_bn = norm_layer(outplanes)\n",
    "\n",
    "        self.res_conv = res_conv\n",
    "        self.drop_block = drop_block\n",
    "        self.drop_path = drop_path\n",
    "\n",
    "    def zero_init_last_bn(self):\n",
    "        nn.init.zeros_(self.bn3.weight)\n",
    "\n",
    "    def forward(self, x, return_x_2=True):\n",
    "        residual = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        if self.drop_block is not None:\n",
    "            x = self.drop_block(x)\n",
    "        x = self.act1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.drop_block is not None:\n",
    "            x = self.drop_block(x)\n",
    "        x2 = self.act2(x)\n",
    "\n",
    "        x = self.conv3(x2)\n",
    "        x = self.bn3(x)\n",
    "        if self.drop_block is not None:\n",
    "            x = self.drop_block(x)\n",
    "\n",
    "        if self.drop_path is not None:\n",
    "            x = self.drop_path(x)\n",
    "\n",
    "        if self.res_conv:\n",
    "            residual = self.residual_conv(residual)\n",
    "            residual = self.residual_bn(residual)\n",
    "\n",
    "        x += residual\n",
    "        x = self.act3(x)\n",
    "\n",
    "        if return_x_2:\n",
    "            return x, x2\n",
    "        else:\n",
    "            return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conformer(nn.Module):\n",
    "    def __init__(self, in_chans=3, num_classes=1000, base_channel=64, channel_ratio=4):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Classifier head\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv_cls_head = nn.Linear(int(256 * channel_ratio), num_classes)\n",
    "\n",
    "        # Stem stage: get the feature maps by conv block (copied form resnet.py)\n",
    "        self.conv1 = nn.Conv2d(in_chans, 64, kernel_size=7, stride=2, padding=3, bias=False)  # 1 / 2 [112, 112]\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.act1 = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # 1 / 4 [56, 56]\n",
    "\n",
    "        # 1 stage\n",
    "        stage_1_channel = int(base_channel * channel_ratio)\n",
    "        self.conv_1 = ConvBlock(inplanes=64, outplanes=stage_1_channel, res_conv=True, stride=1)\n",
    "\n",
    "        stage_2_channel = int(base_channel * channel_ratio * 2)\n",
    "        # 2 stage\n",
    "        self.conv_2 = ConvBlock(inplanes=stage_1_channel, outplanes=stage_2_channel, res_conv=True, stride=2)\n",
    "\n",
    "        stage_3_channel = int(base_channel * channel_ratio * 2 * 2)\n",
    "        # 3 stage\n",
    "        self.conv_3 = ConvBlock(inplanes=stage_2_channel, outplanes=stage_3_channel, res_conv=True, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Stem stage [N, 3, 224, 224] -> [N, 64, 56, 56]\n",
    "        x = self.maxpool(self.act1(self.bn1(self.conv1(x))))\n",
    "\n",
    "        # 1 stage\n",
    "        x, _ = self.conv_1(x)\n",
    "\n",
    "        # 2 stage\n",
    "        x, _ = self.conv_2(x)\n",
    "\n",
    "        # 3 stage\n",
    "        x, _ = self.conv_3(x)\n",
    "\n",
    "        # conv classification\n",
    "        x_p = self.pooling(x).flatten(1)\n",
    "        conv_cls = self.conv_cls_head(x_p)\n",
    "\n",
    "        return conv_cls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Conformer(patch_size=16, channel_ratio=6, embed_dim=576, depth=12,\n",
    "                      num_heads=9, mlp_ratio=4, qkv_bias=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graspenv",
   "language": "python",
   "name": "graspenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
